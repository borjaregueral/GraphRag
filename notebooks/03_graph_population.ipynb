{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import polars as pl\n",
    "from tqdm import tqdm\n",
    "from neo4j import GraphDatabase\n",
    "from neo4j.exceptions import DatabaseError \n",
    "import os\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Variables\n",
    "NEO4J_USERNAME = os.getenv(\"NEO4J_USERNAME\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
    "NEO4J_URI = os.getenv(\"NEO4J_URI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Neo4j\n",
    "driver = GraphDatabase.driver(uri = NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_304, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>post_url</th><th>post_title</th><th>series_number</th><th>blog_date</th><th>blog_title</th><th>chunk_text</th><th>entities</th><th>chunk_id</th></tr><tr><td>str</td><td>str</td><td>str</td><td>date</td><td>str</td><td>str</td><td>list[list[str]]</td><td>str</td></tr></thead><tbody><tr><td>&quot;https://www.acquired.fm/episod…</td><td>&quot;Costco&quot;</td><td>&quot;Season 13, Episode 2&quot;</td><td>2023-08-20</td><td>&quot;The Complete History &amp; Strateg…</td><td>&quot;I don&#x27;t think I have ever been…</td><td>[[&quot;CharlieMunger ?&quot;, &quot;PER&quot;], [&quot;Ben&quot;, &quot;PER&quot;], … [&quot;WarrenBuffett&quot;, &quot;PER&quot;]]</td><td>&quot;5d63560b-dfe3-4702-b309-df4d59…</td></tr><tr><td>&quot;https://www.acquired.fm/episod…</td><td>&quot;Costco&quot;</td><td>&quot;Season 13, Episode 2&quot;</td><td>2023-08-20</td><td>&quot;The Complete History &amp; Strateg…</td><td>&quot;But unlike Costco today, they …</td><td>[[&quot;costco&quot;, &quot;ORG&quot;], [&quot;Fedco&quot;, &quot;ORG&quot;], … [&quot;Fedco&quot;, &quot;ORG&quot;]]</td><td>&quot;516a8513-eb06-441f-92e7-9ed3e3…</td></tr><tr><td>&quot;https://www.acquired.fm/episod…</td><td>&quot;Costco&quot;</td><td>&quot;Season 13, Episode 2&quot;</td><td>2023-08-20</td><td>&quot;The Complete History &amp; Strateg…</td><td>&quot;Jim started as a grocery bagge…</td><td>[[&quot;Jim&quot;, &quot;PER&quot;], [&quot;CraigJelinek&quot;, &quot;PER&quot;], … [&quot;SamWalton&quot;, &quot;PER&quot;]]</td><td>&quot;7fbd4af1-f4b8-450f-b09e-427774…</td></tr><tr><td>&quot;https://www.acquired.fm/episod…</td><td>&quot;Costco&quot;</td><td>&quot;Season 13, Episode 2&quot;</td><td>2023-08-20</td><td>&quot;The Complete History &amp; Strateg…</td><td>&quot;And then they have the greates…</td><td>[[&quot;SanDiego&quot;, &quot;LOC&quot;], [&quot;SanDiegoCityCredit&quot;, &quot;ORG&quot;], … [&quot;costco&quot;, &quot;ORG&quot;]]</td><td>&quot;a7b0b219-119d-4ba4-9b1f-afc68d…</td></tr><tr><td>&quot;https://www.acquired.fm/episod…</td><td>&quot;Costco&quot;</td><td>&quot;Season 13, Episode 2&quot;</td><td>2023-08-20</td><td>&quot;The Complete History &amp; Strateg…</td><td>&quot;In 1982, they do ultimately li…</td><td>[[&quot;NASDAQ&quot;, &quot;MISC&quot;], [&quot;sol&quot;, &quot;PER&quot;], … [&quot;PriceClub&quot;, &quot;ORG&quot;]]</td><td>&quot;ac3c5d77-fc85-43b9-8225-f8c56d…</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;https://www.acquired.fm/episod…</td><td>&quot;Special‚ An Acquirer&#x27;s View in…</td><td>&quot;Season 1, Episode 18&quot;</td><td>2016-08-22</td><td>&quot;Related Episodes&quot;</td><td>&quot;This person who&#x27;s been their r…</td><td>[[&quot;ProfitFromThe&quot;, &quot;MISC&quot;], [&quot;NBA&quot;, &quot;MISC&quot;]]</td><td>&quot;19972d43-1953-4dab-a73e-dfcf79…</td></tr><tr><td>&quot;https://www.acquired.fm/episod…</td><td>&quot;Jet&quot;</td><td>&quot;Season 1, Episode 19&quot;</td><td>2016-08-29</td><td>&quot;Related Episodes&quot;</td><td>&quot;I&#x27;m here at Adobe so feel free…</td><td>[[&quot;Adobe&quot;, &quot;ORG&quot;], [&quot;Barada@Adobe.com&quot;, &quot;ORG&quot;], … [&quot;jet.com&quot;, &quot;ORG&quot;]]</td><td>&quot;03b96574-154a-4bf4-a2e6-382c0d…</td></tr><tr><td>&quot;https://www.acquired.fm/episod…</td><td>&quot;Jet&quot;</td><td>&quot;Season 1, Episode 19&quot;</td><td>2016-08-29</td><td>&quot;Related Episodes&quot;</td><td>&quot;Well, that was what I was goin…</td><td>[[&quot;jet&quot;, &quot;ORG&quot;], [&quot;jet&quot;, &quot;ORG&quot;], … [&quot;american&quot;, &quot;MISC&quot;]]</td><td>&quot;8c4b5ab7-9437-44ff-af01-fc6883…</td></tr><tr><td>&quot;https://www.acquired.fm/episod…</td><td>&quot;Jet&quot;</td><td>&quot;Season 1, Episode 19&quot;</td><td>2016-08-29</td><td>&quot;Related Episodes&quot;</td><td>&quot;Boy, that doesn&#x27;t sound like W…</td><td>[[&quot;jet&quot;, &quot;ORG&quot;], [&quot;Walmart&quot;, &quot;ORG&quot;], … [&quot;Microsoft&quot;, &quot;ORG&quot;]]</td><td>&quot;c9e00451-548e-47fc-b9a9-9dd8b8…</td></tr><tr><td>&quot;https://www.acquired.fm/episod…</td><td>&quot;Jet&quot;</td><td>&quot;Season 1, Episode 19&quot;</td><td>2016-08-29</td><td>&quot;Related Episodes&quot;</td><td>&quot;They&#x27;ve created this totally d…</td><td>[[&quot;jet&quot;, &quot;ORG&quot;], [&quot;jet&quot;, &quot;ORG&quot;], … [&quot;Walmart&quot;, &quot;ORG&quot;]]</td><td>&quot;2efe6f91-a3ab-4189-a601-e184d8…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_304, 8)\n",
       "┌────────────┬────────────┬────────────┬───────────┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ post_url   ┆ post_title ┆ series_num ┆ blog_date ┆ blog_titl ┆ chunk_tex ┆ entities  ┆ chunk_id  │\n",
       "│ ---        ┆ ---        ┆ ber        ┆ ---       ┆ e         ┆ t         ┆ ---       ┆ ---       │\n",
       "│ str        ┆ str        ┆ ---        ┆ date      ┆ ---       ┆ ---       ┆ list[list ┆ str       │\n",
       "│            ┆            ┆ str        ┆           ┆ str       ┆ str       ┆ [str]]    ┆           │\n",
       "╞════════════╪════════════╪════════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ https://ww ┆ Costco     ┆ Season 13, ┆ 2023-08-2 ┆ The       ┆ I don't   ┆ [[\"Charli ┆ 5d63560b- │\n",
       "│ w.acquired ┆            ┆ Episode 2  ┆ 0         ┆ Complete  ┆ think I   ┆ eMunger   ┆ dfe3-4702 │\n",
       "│ .fm/episod ┆            ┆            ┆           ┆ History & ┆ have ever ┆ ?\",       ┆ -b309-df4 │\n",
       "│ …          ┆            ┆            ┆           ┆ Strateg…  ┆ been…     ┆ \"PER\"],   ┆ d59…      │\n",
       "│            ┆            ┆            ┆           ┆           ┆           ┆ […        ┆           │\n",
       "│ https://ww ┆ Costco     ┆ Season 13, ┆ 2023-08-2 ┆ The       ┆ But       ┆ [[\"costco ┆ 516a8513- │\n",
       "│ w.acquired ┆            ┆ Episode 2  ┆ 0         ┆ Complete  ┆ unlike    ┆ \",        ┆ eb06-441f │\n",
       "│ .fm/episod ┆            ┆            ┆           ┆ History & ┆ Costco    ┆ \"ORG\"],   ┆ -92e7-9ed │\n",
       "│ …          ┆            ┆            ┆           ┆ Strateg…  ┆ today,    ┆ [\"Fedco\", ┆ 3e3…      │\n",
       "│            ┆            ┆            ┆           ┆           ┆ they …    ┆ …         ┆           │\n",
       "│ https://ww ┆ Costco     ┆ Season 13, ┆ 2023-08-2 ┆ The       ┆ Jim       ┆ [[\"Jim\",  ┆ 7fbd4af1- │\n",
       "│ w.acquired ┆            ┆ Episode 2  ┆ 0         ┆ Complete  ┆ started   ┆ \"PER\"],   ┆ f4b8-450f │\n",
       "│ .fm/episod ┆            ┆            ┆           ┆ History & ┆ as a      ┆ [\"CraigJe ┆ -b09e-427 │\n",
       "│ …          ┆            ┆            ┆           ┆ Strateg…  ┆ grocery   ┆ line…     ┆ 774…      │\n",
       "│            ┆            ┆            ┆           ┆           ┆ bagge…    ┆           ┆           │\n",
       "│ https://ww ┆ Costco     ┆ Season 13, ┆ 2023-08-2 ┆ The       ┆ And then  ┆ [[\"SanDie ┆ a7b0b219- │\n",
       "│ w.acquired ┆            ┆ Episode 2  ┆ 0         ┆ Complete  ┆ they have ┆ go\",      ┆ 119d-4ba4 │\n",
       "│ .fm/episod ┆            ┆            ┆           ┆ History & ┆ the       ┆ \"LOC\"],   ┆ -9b1f-afc │\n",
       "│ …          ┆            ┆            ┆           ┆ Strateg…  ┆ greates…  ┆ [\"SanDie… ┆ 68d…      │\n",
       "│ https://ww ┆ Costco     ┆ Season 13, ┆ 2023-08-2 ┆ The       ┆ In 1982,  ┆ [[\"NASDAQ ┆ ac3c5d77- │\n",
       "│ w.acquired ┆            ┆ Episode 2  ┆ 0         ┆ Complete  ┆ they do   ┆ \",        ┆ fc85-43b9 │\n",
       "│ .fm/episod ┆            ┆            ┆           ┆ History & ┆ ultimatel ┆ \"MISC\"],  ┆ -8225-f8c │\n",
       "│ …          ┆            ┆            ┆           ┆ Strateg…  ┆ y li…     ┆ [\"sol\",   ┆ 56d…      │\n",
       "│            ┆            ┆            ┆           ┆           ┆           ┆ \"…        ┆           │\n",
       "│ …          ┆ …          ┆ …          ┆ …         ┆ …         ┆ …         ┆ …         ┆ …         │\n",
       "│ https://ww ┆ Special‚   ┆ Season 1,  ┆ 2016-08-2 ┆ Related   ┆ This      ┆ [[\"Profit ┆ 19972d43- │\n",
       "│ w.acquired ┆ An         ┆ Episode 18 ┆ 2         ┆ Episodes  ┆ person    ┆ FromThe\", ┆ 1953-4dab │\n",
       "│ .fm/episod ┆ Acquirer's ┆            ┆           ┆           ┆ who's     ┆ \"MISC\"],  ┆ -a73e-dfc │\n",
       "│ …          ┆ View in…   ┆            ┆           ┆           ┆ been      ┆ [\"…       ┆ f79…      │\n",
       "│            ┆            ┆            ┆           ┆           ┆ their r…  ┆           ┆           │\n",
       "│ https://ww ┆ Jet        ┆ Season 1,  ┆ 2016-08-2 ┆ Related   ┆ I'm here  ┆ [[\"Adobe\" ┆ 03b96574- │\n",
       "│ w.acquired ┆            ┆ Episode 19 ┆ 9         ┆ Episodes  ┆ at Adobe  ┆ , \"ORG\"], ┆ 154a-4bf4 │\n",
       "│ .fm/episod ┆            ┆            ┆           ┆           ┆ so feel   ┆ [\"Barada@ ┆ -a2e6-382 │\n",
       "│ …          ┆            ┆            ┆           ┆           ┆ free…     ┆ Ad…       ┆ c0d…      │\n",
       "│ https://ww ┆ Jet        ┆ Season 1,  ┆ 2016-08-2 ┆ Related   ┆ Well,     ┆ [[\"jet\",  ┆ 8c4b5ab7- │\n",
       "│ w.acquired ┆            ┆ Episode 19 ┆ 9         ┆ Episodes  ┆ that was  ┆ \"ORG\"],   ┆ 9437-44ff │\n",
       "│ .fm/episod ┆            ┆            ┆           ┆           ┆ what I    ┆ [\"jet\",   ┆ -af01-fc6 │\n",
       "│ …          ┆            ┆            ┆           ┆           ┆ was goin… ┆ \"ORG\"…    ┆ 883…      │\n",
       "│ https://ww ┆ Jet        ┆ Season 1,  ┆ 2016-08-2 ┆ Related   ┆ Boy, that ┆ [[\"jet\",  ┆ c9e00451- │\n",
       "│ w.acquired ┆            ┆ Episode 19 ┆ 9         ┆ Episodes  ┆ doesn't   ┆ \"ORG\"],   ┆ 548e-47fc │\n",
       "│ .fm/episod ┆            ┆            ┆           ┆           ┆ sound     ┆ [\"Walmart ┆ -b9a9-9dd │\n",
       "│ …          ┆            ┆            ┆           ┆           ┆ like W…   ┆ \", \"…     ┆ 8b8…      │\n",
       "│ https://ww ┆ Jet        ┆ Season 1,  ┆ 2016-08-2 ┆ Related   ┆ They've   ┆ [[\"jet\",  ┆ 2efe6f91- │\n",
       "│ w.acquired ┆            ┆ Episode 19 ┆ 9         ┆ Episodes  ┆ created   ┆ \"ORG\"],   ┆ a3ab-4189 │\n",
       "│ .fm/episod ┆            ┆            ┆           ┆           ┆ this      ┆ [\"jet\",   ┆ -a601-e18 │\n",
       "│ …          ┆            ┆            ┆           ┆           ┆ totally   ┆ \"ORG\"…    ┆ 4d8…      │\n",
       "│            ┆            ┆            ┆           ┆           ┆ d…        ┆           ┆           │\n",
       "└────────────┴────────────┴────────────┴───────────┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the dataframe form the processing pipeline\n",
    "chunks_df = pl.read_parquet(\"/Users/borja/Documents/Somniumrema/projects/genai/grag/pipeline_outcomes/chunks_df.parquet\")\n",
    "\n",
    "# Select only the columns needed\n",
    "chunks_df = chunks_df[['post_url', 'post_title', 'series_number', 'blog_date', 'blog_title', 'chunk_text', 'entities']]\n",
    "\n",
    "# Add a 'chunk_id' column to the DataFrame with UUIDs (if not already present)\n",
    "if \"chunk_id\" not in chunks_df.columns:\n",
    "    chunks_df = chunks_df.with_columns([\n",
    "        pl.Series(\"chunk_id\", [str(uuid.uuid4()) for _ in range(len(chunks_df))])\n",
    "    ])\n",
    "# Show the first five\n",
    "chunks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>post_url</th><th>post_title</th><th>series_number</th><th>blog_date</th><th>blog_title</th><th>chunk_text</th><th>entities</th><th>chunk_id</th></tr><tr><td>str</td><td>str</td><td>str</td><td>date</td><td>str</td><td>str</td><td>list[list[str]]</td><td>str</td></tr></thead><tbody><tr><td>&quot;https://www.acquired.fm/episod…</td><td>&quot;Airbnb&quot;</td><td>&quot;Season 7, Episode 8&quot;</td><td>2020-12-10</td><td>&quot;‍&quot;</td><td>&quot;Similarly for gifts, it&#x27;s a li…</td><td>[[&quot;lpshow&quot;, &quot;ORG&quot;], [&quot;BenGilbert&quot;, &quot;PER&quot;], … [&quot;DoorDash&quot;, &quot;ORG&quot;]]</td><td>&quot;23c3988a-0d4c-4217-b2b5-8abb1f…</td></tr><tr><td>&quot;https://www.acquired.fm/episod…</td><td>&quot;Airbnb&quot;</td><td>&quot;Season 7, Episode 8&quot;</td><td>2020-12-10</td><td>&quot;‍&quot;</td><td>&quot;But I remember looking at hote…</td><td>[[&quot;WWDC&quot;, &quot;MISC&quot;], [&quot;&quot;, &quot;MISC&quot;], … [&quot;SanFrancisco&quot;, &quot;LOC&quot;]]</td><td>&quot;53bbe17b-cb89-428c-a333-d23071…</td></tr><tr><td>&quot;https://www.acquired.fm/episod…</td><td>&quot;Airbnb&quot;</td><td>&quot;Season 7, Episode 8&quot;</td><td>2020-12-10</td><td>&quot;‍&quot;</td><td>&quot;They&#x27;re still trying to basica…</td><td>[[&quot;cheerio&quot;, &quot;MISC&quot;], [&quot;y&quot;, &quot;ORG&quot;], … [&quot;JeffBezos&quot;, &quot;PER&quot;]]</td><td>&quot;272416df-4896-4572-bc51-74b65b…</td></tr><tr><td>&quot;https://www.acquired.fm/episod…</td><td>&quot;Airbnb&quot;</td><td>&quot;Season 7, Episode 8&quot;</td><td>2020-12-10</td><td>&quot;‍&quot;</td><td>&quot;For something that seemed like…</td><td>[[&quot;Sequoia&quot;, &quot;ORG&quot;], [&quot;Airbnb&quot;, &quot;ORG&quot;], … [&quot;Facebook&quot;, &quot;MISC&quot;]]</td><td>&quot;59d69994-e9fb-42a4-bb84-71ad34…</td></tr><tr><td>&quot;https://www.acquired.fm/episod…</td><td>&quot;Airbnb&quot;</td><td>&quot;Season 7, Episode 8&quot;</td><td>2020-12-10</td><td>&quot;‍&quot;</td><td>&quot;Never heard of a startup winni…</td><td>[[&quot;NobelPeacePrize ,&quot;, &quot;MISC&quot;], [&quot;UpstartstoBrad&quot;, &quot;MISC&quot;], … [&quot;Samwer&quot;, &quot;PER&quot;]]</td><td>&quot;dc468788-2fba-4b4e-85f9-b220e3…</td></tr><tr><td>&quot;https://www.acquired.fm/episod…</td><td>&quot;Airbnb&quot;</td><td>&quot;Season 7, Episode 8&quot;</td><td>2020-12-10</td><td>&quot;‍&quot;</td><td>&quot;Which we&#x27;ve alluded to in our …</td><td>[[&quot;ipo&quot;, &quot;MISC&quot;]]</td><td>&quot;7c38d48f-de75-4040-a8ec-e7070f…</td></tr><tr><td>&quot;https://www.acquired.fm/episod…</td><td>&quot;Airbnb&quot;</td><td>&quot;Season 7, Episode 8&quot;</td><td>2020-12-10</td><td>&quot;‍&quot;</td><td>&quot;We do have some more nuggets h…</td><td>[[&quot;s1&quot;, &quot;MISC&quot;], [&quot;bamboo&quot;, &quot;ORG&quot;], … [&quot;BrianChesky&quot;, &quot;PER&quot;]]</td><td>&quot;d7a18284-743c-470e-b625-f67766…</td></tr><tr><td>&quot;https://www.acquired.fm/episod…</td><td>&quot;Airbnb&quot;</td><td>&quot;Season 7, Episode 8&quot;</td><td>2020-12-10</td><td>&quot;‍&quot;</td><td>&quot;All markets are supply and dem…</td><td>[[&quot;Airbnb&quot;, &quot;ORG&quot;], [&quot;Airbnb&quot;, &quot;ORG&quot;], … [&quot;Airbnb&quot;, &quot;ORG&quot;]]</td><td>&quot;13218b14-8d65-418a-aad6-45bf6e…</td></tr><tr><td>&quot;https://www.acquired.fm/episod…</td><td>&quot;Airbnb&quot;</td><td>&quot;Season 7, Episode 8&quot;</td><td>2020-12-10</td><td>&quot;‍&quot;</td><td>&quot;For consumers, it&#x27;s very easy …</td><td>[[&quot;uber&quot;, &quot;MISC&quot;], [&quot;Airbnb&quot;, &quot;MISC&quot;], … [&quot;Airbnb&quot;, &quot;ORG&quot;]]</td><td>&quot;923043ce-f03b-46cd-83b9-17d535…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 8)\n",
       "┌────────────┬────────────┬────────────┬───────────┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ post_url   ┆ post_title ┆ series_num ┆ blog_date ┆ blog_titl ┆ chunk_tex ┆ entities  ┆ chunk_id  │\n",
       "│ ---        ┆ ---        ┆ ber        ┆ ---       ┆ e         ┆ t         ┆ ---       ┆ ---       │\n",
       "│ str        ┆ str        ┆ ---        ┆ date      ┆ ---       ┆ ---       ┆ list[list ┆ str       │\n",
       "│            ┆            ┆ str        ┆           ┆ str       ┆ str       ┆ [str]]    ┆           │\n",
       "╞════════════╪════════════╪════════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ https://ww ┆ Airbnb     ┆ Season 7,  ┆ 2020-12-1 ┆ ‍          ┆ Similarly ┆ [[\"lpshow ┆ 23c3988a- │\n",
       "│ w.acquired ┆            ┆ Episode 8  ┆ 0         ┆           ┆ for       ┆ \",        ┆ 0d4c-4217 │\n",
       "│ .fm/episod ┆            ┆            ┆           ┆           ┆ gifts,    ┆ \"ORG\"],   ┆ -b2b5-8ab │\n",
       "│ …          ┆            ┆            ┆           ┆           ┆ it's a    ┆ [\"BenGilb ┆ b1f…      │\n",
       "│            ┆            ┆            ┆           ┆           ┆ li…       ┆ e…        ┆           │\n",
       "│ https://ww ┆ Airbnb     ┆ Season 7,  ┆ 2020-12-1 ┆ ‍          ┆ But I     ┆ [[\"WWDC\", ┆ 53bbe17b- │\n",
       "│ w.acquired ┆            ┆ Episode 8  ┆ 0         ┆           ┆ remember  ┆ \"MISC\"],  ┆ cb89-428c │\n",
       "│ .fm/episod ┆            ┆            ┆           ┆           ┆ looking   ┆ [\"\",      ┆ -a333-d23 │\n",
       "│ …          ┆            ┆            ┆           ┆           ┆ at hote…  ┆ \"MISC\"…   ┆ 071…      │\n",
       "│ https://ww ┆ Airbnb     ┆ Season 7,  ┆ 2020-12-1 ┆ ‍          ┆ They're   ┆ [[\"cheeri ┆ 272416df- │\n",
       "│ w.acquired ┆            ┆ Episode 8  ┆ 0         ┆           ┆ still     ┆ o\",       ┆ 4896-4572 │\n",
       "│ .fm/episod ┆            ┆            ┆           ┆           ┆ trying to ┆ \"MISC\"],  ┆ -bc51-74b │\n",
       "│ …          ┆            ┆            ┆           ┆           ┆ basica…   ┆ [\"y\", \"O… ┆ 65b…      │\n",
       "│ https://ww ┆ Airbnb     ┆ Season 7,  ┆ 2020-12-1 ┆ ‍          ┆ For       ┆ [[\"Sequoi ┆ 59d69994- │\n",
       "│ w.acquired ┆            ┆ Episode 8  ┆ 0         ┆           ┆ something ┆ a\",       ┆ e9fb-42a4 │\n",
       "│ .fm/episod ┆            ┆            ┆           ┆           ┆ that      ┆ \"ORG\"],   ┆ -bb84-71a │\n",
       "│ …          ┆            ┆            ┆           ┆           ┆ seemed    ┆ [\"Airbnb\" ┆ d34…      │\n",
       "│            ┆            ┆            ┆           ┆           ┆ like…     ┆ …         ┆           │\n",
       "│ https://ww ┆ Airbnb     ┆ Season 7,  ┆ 2020-12-1 ┆ ‍          ┆ Never     ┆ [[\"NobelP ┆ dc468788- │\n",
       "│ w.acquired ┆            ┆ Episode 8  ┆ 0         ┆           ┆ heard of  ┆ eacePrize ┆ 2fba-4b4e │\n",
       "│ .fm/episod ┆            ┆            ┆           ┆           ┆ a startup ┆ ,\",       ┆ -85f9-b22 │\n",
       "│ …          ┆            ┆            ┆           ┆           ┆ winni…    ┆ \"MISC\"]…  ┆ 0e3…      │\n",
       "│ https://ww ┆ Airbnb     ┆ Season 7,  ┆ 2020-12-1 ┆ ‍          ┆ Which     ┆ [[\"ipo\",  ┆ 7c38d48f- │\n",
       "│ w.acquired ┆            ┆ Episode 8  ┆ 0         ┆           ┆ we've     ┆ \"MISC\"]]  ┆ de75-4040 │\n",
       "│ .fm/episod ┆            ┆            ┆           ┆           ┆ alluded   ┆           ┆ -a8ec-e70 │\n",
       "│ …          ┆            ┆            ┆           ┆           ┆ to in our ┆           ┆ 70f…      │\n",
       "│            ┆            ┆            ┆           ┆           ┆ …         ┆           ┆           │\n",
       "│ https://ww ┆ Airbnb     ┆ Season 7,  ┆ 2020-12-1 ┆ ‍          ┆ We do     ┆ [[\"s1\",   ┆ d7a18284- │\n",
       "│ w.acquired ┆            ┆ Episode 8  ┆ 0         ┆           ┆ have some ┆ \"MISC\"],  ┆ 743c-470e │\n",
       "│ .fm/episod ┆            ┆            ┆           ┆           ┆ more      ┆ [\"bamboo\" ┆ -b625-f67 │\n",
       "│ …          ┆            ┆            ┆           ┆           ┆ nuggets   ┆ , \"O…     ┆ 766…      │\n",
       "│            ┆            ┆            ┆           ┆           ┆ h…        ┆           ┆           │\n",
       "│ https://ww ┆ Airbnb     ┆ Season 7,  ┆ 2020-12-1 ┆ ‍          ┆ All       ┆ [[\"Airbnb ┆ 13218b14- │\n",
       "│ w.acquired ┆            ┆ Episode 8  ┆ 0         ┆           ┆ markets   ┆ \",        ┆ 8d65-418a │\n",
       "│ .fm/episod ┆            ┆            ┆           ┆           ┆ are       ┆ \"ORG\"],   ┆ -aad6-45b │\n",
       "│ …          ┆            ┆            ┆           ┆           ┆ supply    ┆ [\"Airbnb\" ┆ f6e…      │\n",
       "│            ┆            ┆            ┆           ┆           ┆ and dem…  ┆ ,…        ┆           │\n",
       "│ https://ww ┆ Airbnb     ┆ Season 7,  ┆ 2020-12-1 ┆ ‍          ┆ For consu ┆ [[\"uber\", ┆ 923043ce- │\n",
       "│ w.acquired ┆            ┆ Episode 8  ┆ 0         ┆           ┆ mers,     ┆ \"MISC\"],  ┆ f03b-46cd │\n",
       "│ .fm/episod ┆            ┆            ┆           ┆           ┆ it's very ┆ [\"Airbnb\" ┆ -83b9-17d │\n",
       "│ …          ┆            ┆            ┆           ┆           ┆ easy …    ┆ , …       ┆ 535…      │\n",
       "└────────────┴────────────┴────────────┴───────────┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks_df.filter(pl.col(\"post_title\") == \"Airbnb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the full-text index\n",
    "# with driver.session() as session:\n",
    "#     session.run(\n",
    "#         \"CREATE FULLTEXT INDEX chunk_fulltext_index FOR (c:Chunk) ON EACH [c.text] OPTIONS { indexConfig: { `fulltext.analyzer`: 'standard' } };\"\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for bulk upload with DISTINCT podcast nodes\n",
    "podcast_nodes = []\n",
    "chunk_nodes = []\n",
    "belongs_to_rels = []\n",
    "entity_nodes = []\n",
    "mentions_rels = []\n",
    "\n",
    "# Create sets to keep track of unique nodes and relationships\n",
    "unique_podcast_nodes = set()\n",
    "unique_chunk_nodes = set()\n",
    "unique_belongs_to_rels = set()\n",
    "unique_entity_nodes = set()\n",
    "unique_mentions_rels = set()\n",
    "\n",
    "for row in chunks_df.iter_rows(named=True):\n",
    "    # --- Podcast Nodes ---\n",
    "    \n",
    "    # Create a key for the podcast based on its identifying attributes\n",
    "    podcast_key = (row['post_url'], row['post_title'])  # Use a tuple of relevant attributes\n",
    "\n",
    "    if podcast_key not in unique_podcast_nodes:\n",
    "        podcast_node = {\n",
    "            \"podcast_id\": str(uuid.uuid4()),\n",
    "            \"post_url\": row['post_url'],\n",
    "            \"post_title\": row['post_title'],\n",
    "            \"blog_date\": row['blog_date'],\n",
    "            \"blog_title\": row['blog_title'],\n",
    "            \"series_number\": row['series_number']\n",
    "        }\n",
    "        podcast_nodes.append(podcast_node)\n",
    "        unique_podcast_nodes.add(podcast_key)\n",
    "\n",
    "    # --- Chunk Nodes ---\n",
    "    chunk_node = {\n",
    "        \"chunk_id\": row['chunk_id'],\n",
    "        \"text\": row['chunk_text']\n",
    "    }\n",
    "    if tuple(chunk_node.items()) not in unique_chunk_nodes:\n",
    "        chunk_nodes.append(chunk_node)\n",
    "        unique_chunk_nodes.add(tuple(chunk_node.items()))\n",
    "\n",
    "    # --- BELONGS_TO Relationships ---\n",
    "    belongs_to_rel = {\n",
    "        \"chunk_id\": row['chunk_id'],\n",
    "        \"podcast_id\": podcast_node['podcast_id']  # Use the podcast_id from the podcast_node\n",
    "    }\n",
    "    if tuple(belongs_to_rel.items()) not in unique_belongs_to_rels:\n",
    "        belongs_to_rels.append(belongs_to_rel)\n",
    "        unique_belongs_to_rels.add(tuple(belongs_to_rel.items()))\n",
    "\n",
    "    # --- Entity Nodes and MENTIONS Relationships ---\n",
    "    for entity, label in row['entities']:\n",
    "        entity_node = {\n",
    "            \"name\": entity,\n",
    "            \"label\": label\n",
    "        }\n",
    "        if tuple(entity_node.items()) not in unique_entity_nodes:\n",
    "            entity_nodes.append(entity_node)\n",
    "            unique_entity_nodes.add(tuple(entity_node.items()))\n",
    "\n",
    "        mentions_rel = {\n",
    "            \"chunk_id\": row['chunk_id'],\n",
    "            \"entity_name\": entity,\n",
    "            \"entity_label\": label\n",
    "        }\n",
    "        if tuple(mentions_rel.items()) not in unique_mentions_rels:\n",
    "            mentions_rels.append(mentions_rel)\n",
    "            unique_mentions_rels.add(tuple(mentions_rel.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199, 1304, 1304, 4579, 9365)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of nodes and relationships\n",
    "len(podcast_nodes), len(chunk_nodes), len(belongs_to_rels), len(entity_nodes), len(mentions_rels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned and Deduplicated Nodes:\n",
      "{'name': 'Play Station', 'label': None}\n",
      "{'name': 'Playstation', 'label': None}\n",
      "{'name': 'Play Station2', 'label': None}\n",
      "{'name': 'Grand Theft Auto5', 'label': None}\n",
      "{'name': 'Grand Theft Auto', 'label': None}\n",
      "{'name': 'Google Docs', 'label': None}\n",
      "{'name': 'Google Doc', 'label': None}\n",
      "{'name': 'Vision Fund', 'label': None}\n",
      "{'name': 'Vision Fund1', 'label': None}\n",
      "{'name': 'Gearsof Wars', 'label': None}\n",
      "{'name': 'Gearsof War', 'label': None}\n",
      "{'name': 'Buffett Partnership', 'label': None}\n",
      "{'name': 'Buffett Partnerships', 'label': None}\n",
      "{'name': 'Buildhopper', 'label': None}\n",
      "{'name': 'Build Hopper', 'label': None}\n",
      "{'name': 'Taylorbarada', 'label': None}\n",
      "{'name': 'Taylor Barada', 'label': None}\n",
      "{'name': 'Donvalentine', 'label': None}\n",
      "{'name': 'Don Valentine', 'label': None}\n",
      "{'name': 'Charliemunger', 'label': None}\n",
      "{'name': 'Charlie Munger', 'label': None}\n",
      "{'name': 'The Soprano', 'label': None}\n",
      "{'name': 'The Sopranos', 'label': None}\n",
      "{'name': 'Invest Like The', 'label': None}\n",
      "{'name': 'Invest Likethe', 'label': None}\n",
      "{'name': 'Skunkworks', 'label': None}\n",
      "{'name': 'Skunk Works', 'label': None}\n",
      "{'name': 'Siliconvalley', 'label': None}\n",
      "{'name': 'Silicon Valley', 'label': None}\n",
      "{'name': 'Mark Zuckerberg', 'label': None}\n",
      "{'name': 'Marck Zuckerberg', 'label': None}\n",
      "{'name': 'Java Script', 'label': None}\n",
      "{'name': 'Javascript', 'label': None}\n",
      "{'name': 'Blizzard Entertainment', 'label': None}\n",
      "{'name': 'Blizzardentertainment', 'label': None}\n",
      "{'name': 'Four Square', 'label': None}\n",
      "{'name': 'Foursquare', 'label': None}\n",
      "{'name': 'Raspberry Pis', 'label': None}\n",
      "{'name': 'Raspberry Pi', 'label': None}\n",
      "{'name': 'Pitch Books', 'label': None}\n",
      "{'name': 'Pitch Book', 'label': None}\n",
      "{'name': 'Davidrosenthal', 'label': None}\n",
      "{'name': 'David Rosenthal', 'label': None}\n",
      "{'name': 'Virgin Galactic', 'label': None}\n",
      "{'name': 'Virgingalactic', 'label': None}\n",
      "{'name': 'Square Space', 'label': None}\n",
      "{'name': 'Squarespace', 'label': None}\n",
      "{'name': 'Silicon Alley', 'label': None}\n",
      "{'name': 'Silicon Valley', 'label': None}\n",
      "{'name': 'North American', 'label': None}\n",
      "{'name': 'North America', 'label': None}\n",
      "\n",
      "Identified Duplicates:\n",
      "Canonical Name: Play Station\n",
      "  - Duplicate: Playstation\n",
      "  - Duplicate: Play Station2\n",
      "Canonical Name: Grand Theft Auto5\n",
      "  - Duplicate: Grand Theft Auto\n",
      "Canonical Name: Google Docs\n",
      "  - Duplicate: Google Doc\n",
      "Canonical Name: Vision Fund\n",
      "  - Duplicate: Vision Fund1\n",
      "Canonical Name: Gearsof Wars\n",
      "  - Duplicate: Gearsof War\n",
      "Canonical Name: Buffett Partnership\n",
      "  - Duplicate: Buffett Partnerships\n",
      "Canonical Name: Buildhopper\n",
      "  - Duplicate: Build Hopper\n",
      "Canonical Name: Taylorbarada\n",
      "  - Duplicate: Taylor Barada\n",
      "Canonical Name: Donvalentine\n",
      "  - Duplicate: Don Valentine\n",
      "Canonical Name: Charliemunger\n",
      "  - Duplicate: Charlie Munger\n",
      "Canonical Name: The Soprano\n",
      "  - Duplicate: The Sopranos\n",
      "Canonical Name: Invest Like The\n",
      "  - Duplicate: Invest Likethe\n",
      "Canonical Name: Skunkworks\n",
      "  - Duplicate: Skunk Works\n",
      "Canonical Name: Siliconvalley\n",
      "  - Duplicate: Silicon Valley\n",
      "Canonical Name: Mark Zuckerberg\n",
      "  - Duplicate: Marck Zuckerberg\n",
      "Canonical Name: Java Script\n",
      "  - Duplicate: Javascript\n",
      "Canonical Name: Blizzard Entertainment\n",
      "  - Duplicate: Blizzardentertainment\n",
      "Canonical Name: Four Square\n",
      "  - Duplicate: Foursquare\n",
      "Canonical Name: Raspberry Pis\n",
      "  - Duplicate: Raspberry Pi\n",
      "Canonical Name: Pitch Books\n",
      "  - Duplicate: Pitch Book\n",
      "Canonical Name: Davidrosenthal\n",
      "  - Duplicate: David Rosenthal\n",
      "Canonical Name: Virgin Galactic\n",
      "  - Duplicate: Virgingalactic\n",
      "Canonical Name: Square Space\n",
      "  - Duplicate: Squarespace\n",
      "Canonical Name: Silicon Alley\n",
      "  - Duplicate: Silicon Valley\n",
      "Canonical Name: North American\n",
      "  - Duplicate: North America\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from rapidfuzz import fuzz\n",
    "from collections import defaultdict\n",
    "import polars as pl\n",
    "\n",
    "def clean_node_name(name):\n",
    "    \"\"\"\n",
    "    Cleans the node name by:\n",
    "    - Removing extraneous punctuation\n",
    "    - Adding spaces before uppercase letters for better readability\n",
    "    - Standardizing to title case\n",
    "    \"\"\"\n",
    "    if not isinstance(name, str):\n",
    "        return name  # Return as is if not a string\n",
    "    \n",
    "    name = re.sub(r'[^\\w\\s]', '', name)  # Remove punctuation\n",
    "    name = re.sub(r'(?<!^)(?=[A-Z])', ' ', name)  # Space before uppercase\n",
    "    name = name.title()  # Title case\n",
    "    return ' '.join(name.split())  # Remove extra spaces\n",
    "\n",
    "def standardize_nodes(nodes, name_column=\"name\"):\n",
    "    \"\"\"\n",
    "    Applies cleaning to all node names and adds standardized name fields.\n",
    "    \"\"\"\n",
    "    df = pl.DataFrame(nodes)\n",
    "    \n",
    "    # Clean and standardize node names\n",
    "    df = df.with_columns([\n",
    "        pl.col(name_column).map_elements(clean_node_name, return_dtype=pl.Utf8).alias(\"cleaned_name\"),\n",
    "        pl.col(name_column).map_elements(lambda x: clean_node_name(x).lower() if isinstance(x, str) else x, return_dtype=pl.Utf8).alias(\"cleaned_name_lower\")\n",
    "    ])\n",
    "    return df\n",
    "\n",
    "def identify_duplicates(df, similarity_threshold=90):\n",
    "    \"\"\"\n",
    "    Identifies duplicates based on name similarity.\n",
    "    \"\"\"\n",
    "    duplicates = defaultdict(list)\n",
    "    unique_names = df[\"cleaned_name\"].unique().to_list()\n",
    "    \n",
    "    for i, name in enumerate(unique_names):\n",
    "        for other_name in unique_names[i + 1:]:\n",
    "            similarity = fuzz.ratio(name.lower(), other_name.lower())\n",
    "            if similarity >= similarity_threshold:\n",
    "                duplicates[name].append(other_name)\n",
    "    return duplicates\n",
    "\n",
    "def merge_duplicates(df, duplicates):\n",
    "    \"\"\"\n",
    "    Merges duplicate entries by selecting a canonical name and updating labels.\n",
    "    \"\"\"\n",
    "    merged_entries = []\n",
    "    for canonical, dup_list in duplicates.items():\n",
    "        labels = df.filter(pl.col(\"cleaned_name\") == canonical)[\"label\"].to_list()\n",
    "        most_common_label = max(set(labels), key=labels.count) if labels else 'MISC'\n",
    "        merged_entries.append({'name': canonical, 'label': most_common_label})\n",
    "        \n",
    "        for dup in dup_list:\n",
    "            dup_labels = df.filter(pl.col(\"cleaned_name\") == dup)[\"label\"].to_list()\n",
    "            dup_most_common_label = max(set(dup_labels), key=dup_labels.count) if dup_labels else 'MISC'\n",
    "            merged_entries.append({'name': dup, 'label': dup_most_common_label})\n",
    "    \n",
    "    merged_df = pl.DataFrame(merged_entries)\n",
    "    return merged_df\n",
    "\n",
    "def correct_labels(merged_df):\n",
    "    \"\"\"\n",
    "    Corrects misclassified labels based on business rules.\n",
    "    \"\"\"\n",
    "    label_corrections = {\n",
    "        'Sol': 'PER',\n",
    "    }\n",
    "    \n",
    "    merged_df = merged_df.with_columns(\n",
    "        pl.col(\"label\").map_elements(\n",
    "            lambda label, name: label_corrections.get(name.lower(), label) \n",
    "            if name.lower() in label_corrections else label, \n",
    "            return_dtype=pl.Utf8\n",
    "        )\n",
    "    )\n",
    "    return merged_df\n",
    "\n",
    "def clean_and_deduplicate(nodes, similarity_threshold=90):\n",
    "    df = standardize_nodes(nodes)\n",
    "    duplicates = identify_duplicates(df, similarity_threshold=similarity_threshold)\n",
    "    merged_df = merge_duplicates(df, duplicates)\n",
    "    \n",
    "    # Ensure merged_df has the necessary columns\n",
    "    if \"name\" not in merged_df.columns:\n",
    "        merged_df = merged_df.with_columns(pl.col(\"cleaned_name\").alias(\"name\"))\n",
    "    if \"label\" not in merged_df.columns:\n",
    "        merged_df = merged_df.with_columns(pl.lit(\"MISC\").alias(\"label\"))\n",
    "    \n",
    "    corrected_df = correct_labels(merged_df)\n",
    "    return corrected_df.select([\"name\", \"label\"]).to_dicts(), duplicates\n",
    "\n",
    "# Execution\n",
    "cleaned_nodes, duplicates_info = clean_and_deduplicate(entity_nodes, similarity_threshold=95)\n",
    "\n",
    "# Output cleaned nodes and duplicates\n",
    "print(\"Cleaned and Deduplicated Nodes:\")\n",
    "for node in cleaned_nodes:\n",
    "    print(node)\n",
    "\n",
    "if duplicates_info:\n",
    "    print(\"\\nIdentified Duplicates:\")\n",
    "    for canonical, dup_list in duplicates_info.items():\n",
    "        print(f\"Canonical Name: {canonical}\")\n",
    "        for dup in dup_list:\n",
    "            print(f\"  - Duplicate: {dup}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Bulk upload nodes and relationships\n",
    "# with driver.session() as session:\n",
    "#     # --- Podcast Nodes ---\n",
    "#     for i in tqdm(range(0, len(podcast_nodes), 1000), desc=\"Creating Podcast Nodes\"):\n",
    "#         batch = podcast_nodes[i:i + 1000]\n",
    "#         session.run(\n",
    "#             \"\"\"\n",
    "#             UNWIND $podcast_nodes AS podcast\n",
    "#             MERGE (p:Podcast {podcast_id: podcast.podcast_id})\n",
    "#             SET p.post_url = podcast.post_url, \n",
    "#                 p.post_title = podcast.post_title,\n",
    "#                 p.blog_date = podcast.blog_date, \n",
    "#                 p.blog_title = podcast.blog_title,\n",
    "#                 p.series_number = podcast.series_number\n",
    "#             \"\"\",\n",
    "#             podcast_nodes=batch\n",
    "#         )\n",
    "\n",
    "#     # --- Chunk Nodes ---\n",
    "#     for i in tqdm(range(0, len(chunk_nodes), 1000), desc=\"Creating Chunk Nodes\"):\n",
    "#         batch = chunk_nodes[i:i + 1000]\n",
    "#         session.run(\n",
    "#             \"\"\"\n",
    "#             UNWIND $chunk_nodes AS chunk\n",
    "#             CREATE (c:Chunk {chunk_id: chunk.chunk_id, text: chunk.text})\n",
    "#             \"\"\",\n",
    "#             chunk_nodes=batch\n",
    "#         )\n",
    "\n",
    "#     # --- BELONGS_TO Relationships ---\n",
    "#     for i in tqdm(range(0, len(belongs_to_rels), 1000), desc=\"Creating BELONGS_TO Relationships\"):\n",
    "#         batch = belongs_to_rels[i:i + 1000]\n",
    "#         session.run(\n",
    "#             \"\"\"\n",
    "#             UNWIND $belongs_to_rels AS rel\n",
    "#             MATCH (c:Chunk {chunk_id: rel.chunk_id})\n",
    "#             MATCH (p:Podcast {podcast_id: rel.podcast_id})\n",
    "#             CREATE (c)-[:BELONGS_TO]->(p)\n",
    "#             \"\"\",\n",
    "#             belongs_to_rels=batch\n",
    "#         )\n",
    "\n",
    "#     # --- Entity Nodes and MENTIONS Relationships ---\n",
    "#     unique_entity_nodes = []\n",
    "#     for entity in entity_nodes:\n",
    "#         if entity not in unique_entity_nodes:\n",
    "#             unique_entity_nodes.append(entity)\n",
    "\n",
    "#     for i in tqdm(range(0, len(unique_entity_nodes), 1000), desc=\"Creating Entity Nodes\"):\n",
    "#         batch = unique_entity_nodes[i:i + 1000]\n",
    "#         session.run(\n",
    "#             \"\"\"\n",
    "#             UNWIND $entity_nodes AS entity\n",
    "#             MERGE (e:Entity {name: entity.name, label: entity.label})  \n",
    "#             \"\"\",\n",
    "#             entity_nodes=batch\n",
    "#         )\n",
    "\n",
    "#     # Create a list to store unique mentions relationships\n",
    "#     unique_mentions_rels = []\n",
    "#     for rel in mentions_rels:\n",
    "#         if rel not in unique_mentions_rels:\n",
    "#             unique_mentions_rels.append(rel)\n",
    "#     for i in tqdm(range(0, len(unique_mentions_rels), 1000), desc=\"Creating MENTIONS Relationships\"):\n",
    "#         batch = unique_mentions_rels[i:i + 1000]\n",
    "#         try:\n",
    "#             session.run(\n",
    "#                 \"\"\"\n",
    "#                 UNWIND $mentions_rels AS rel\n",
    "#                 MATCH (c:Chunk {chunk_id: rel.chunk_id})\n",
    "#                 MATCH (e:Entity {name: rel.entity_name, label: rel.entity_label})  \n",
    "#                 CREATE (c)-[:MENTIONS]->(e)\n",
    "#                 \"\"\",\n",
    "#                 mentions_rels=batch\n",
    "#             )\n",
    "#         except DatabaseError as e:\n",
    "#             if e.code == DatabaseError.Transaction.TransactionCommitFailed:\n",
    "#                 print(f\"Error creating MENTIONS relationships (batch {i // 1000 + 1}): {e.message}\")\n",
    "#                 # Handle the error (e.g., log the error, skip the batch, retry with smaller batches)\n",
    "#             else:\n",
    "#                 raise e  # Raise other types of errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grag-EOKyDehK-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
