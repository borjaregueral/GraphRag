{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import polars as pl\n",
    "from tqdm import tqdm\n",
    "from neo4j import GraphDatabase\n",
    "from neo4j.exceptions import DatabaseError \n",
    "import os\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Variables\n",
    "NEO4J_USERNAME = os.getenv(\"NEO4J_USERNAME\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
    "NEO4J_URI = os.getenv(\"NEO4J_URI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Neo4j\n",
    "driver = GraphDatabase.driver(uri = NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_304, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>post_url</th><th>post_title</th><th>series_number</th><th>blog_date</th><th>blog_title</th><th>chunk_text</th><th>entities</th><th>chunk_id</th></tr><tr><td>str</td><td>str</td><td>str</td><td>date</td><td>str</td><td>str</td><td>list[list[str]]</td><td>str</td></tr></thead><tbody><tr><td>&quot;https://www.acquired.fm/episod…</td><td>&quot;Costco&quot;</td><td>&quot;Season 13, Episode 2&quot;</td><td>2023-08-20</td><td>&quot;The Complete History &amp; Strateg…</td><td>&quot;I don&#x27;t think I have ever been…</td><td>[[&quot;CharlieMunger ?&quot;, &quot;PER&quot;], [&quot;Ben&quot;, &quot;PER&quot;], … [&quot;WarrenBuffett&quot;, &quot;PER&quot;]]</td><td>&quot;9a2f203c-f18d-4f1b-965d-1bed0e…</td></tr><tr><td>&quot;https://www.acquired.fm/episod…</td><td>&quot;Costco&quot;</td><td>&quot;Season 13, Episode 2&quot;</td><td>2023-08-20</td><td>&quot;The Complete History &amp; Strateg…</td><td>&quot;But unlike Costco today, they …</td><td>[[&quot;costco&quot;, &quot;ORG&quot;], [&quot;Fedco&quot;, &quot;ORG&quot;], … [&quot;Fedco&quot;, &quot;ORG&quot;]]</td><td>&quot;87c6fd73-b811-423f-a25b-9a0a53…</td></tr><tr><td>&quot;https://www.acquired.fm/episod…</td><td>&quot;Costco&quot;</td><td>&quot;Season 13, Episode 2&quot;</td><td>2023-08-20</td><td>&quot;The Complete History &amp; Strateg…</td><td>&quot;Jim started as a grocery bagge…</td><td>[[&quot;Jim&quot;, &quot;PER&quot;], [&quot;CraigJelinek&quot;, &quot;PER&quot;], … [&quot;SamWalton&quot;, &quot;PER&quot;]]</td><td>&quot;ba860315-b8c4-4ee2-9bdc-95d2a1…</td></tr><tr><td>&quot;https://www.acquired.fm/episod…</td><td>&quot;Costco&quot;</td><td>&quot;Season 13, Episode 2&quot;</td><td>2023-08-20</td><td>&quot;The Complete History &amp; Strateg…</td><td>&quot;And then they have the greates…</td><td>[[&quot;SanDiego&quot;, &quot;LOC&quot;], [&quot;SanDiegoCityCredit&quot;, &quot;ORG&quot;], … [&quot;costco&quot;, &quot;ORG&quot;]]</td><td>&quot;19b6d3ed-55a6-4424-bdb6-781004…</td></tr><tr><td>&quot;https://www.acquired.fm/episod…</td><td>&quot;Costco&quot;</td><td>&quot;Season 13, Episode 2&quot;</td><td>2023-08-20</td><td>&quot;The Complete History &amp; Strateg…</td><td>&quot;In 1982, they do ultimately li…</td><td>[[&quot;NASDAQ&quot;, &quot;MISC&quot;], [&quot;sol&quot;, &quot;PER&quot;], … [&quot;PriceClub&quot;, &quot;ORG&quot;]]</td><td>&quot;46581ec4-ff10-42e9-b104-ee092c…</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;https://www.acquired.fm/episod…</td><td>&quot;Special‚ An Acquirer&#x27;s View in…</td><td>&quot;Season 1, Episode 18&quot;</td><td>2016-08-22</td><td>&quot;Related Episodes&quot;</td><td>&quot;This person who&#x27;s been their r…</td><td>[[&quot;ProfitFromThe&quot;, &quot;MISC&quot;], [&quot;NBA&quot;, &quot;MISC&quot;]]</td><td>&quot;ae6a1ceb-bc15-4219-a11d-44699b…</td></tr><tr><td>&quot;https://www.acquired.fm/episod…</td><td>&quot;Jet&quot;</td><td>&quot;Season 1, Episode 19&quot;</td><td>2016-08-29</td><td>&quot;Related Episodes&quot;</td><td>&quot;I&#x27;m here at Adobe so feel free…</td><td>[[&quot;Adobe&quot;, &quot;ORG&quot;], [&quot;Barada@Adobe.com&quot;, &quot;ORG&quot;], … [&quot;jet.com&quot;, &quot;ORG&quot;]]</td><td>&quot;5852936f-2872-4abd-81a6-9780c6…</td></tr><tr><td>&quot;https://www.acquired.fm/episod…</td><td>&quot;Jet&quot;</td><td>&quot;Season 1, Episode 19&quot;</td><td>2016-08-29</td><td>&quot;Related Episodes&quot;</td><td>&quot;Well, that was what I was goin…</td><td>[[&quot;jet&quot;, &quot;ORG&quot;], [&quot;jet&quot;, &quot;ORG&quot;], … [&quot;american&quot;, &quot;MISC&quot;]]</td><td>&quot;7391fc5e-47b5-4a41-b462-6e8532…</td></tr><tr><td>&quot;https://www.acquired.fm/episod…</td><td>&quot;Jet&quot;</td><td>&quot;Season 1, Episode 19&quot;</td><td>2016-08-29</td><td>&quot;Related Episodes&quot;</td><td>&quot;Boy, that doesn&#x27;t sound like W…</td><td>[[&quot;jet&quot;, &quot;ORG&quot;], [&quot;Walmart&quot;, &quot;ORG&quot;], … [&quot;Microsoft&quot;, &quot;ORG&quot;]]</td><td>&quot;8b6c4771-790f-44c8-9921-b9b387…</td></tr><tr><td>&quot;https://www.acquired.fm/episod…</td><td>&quot;Jet&quot;</td><td>&quot;Season 1, Episode 19&quot;</td><td>2016-08-29</td><td>&quot;Related Episodes&quot;</td><td>&quot;They&#x27;ve created this totally d…</td><td>[[&quot;jet&quot;, &quot;ORG&quot;], [&quot;jet&quot;, &quot;ORG&quot;], … [&quot;Walmart&quot;, &quot;ORG&quot;]]</td><td>&quot;2bb84e43-f312-41d0-85cd-172265…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_304, 8)\n",
       "┌────────────┬────────────┬────────────┬───────────┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ post_url   ┆ post_title ┆ series_num ┆ blog_date ┆ blog_titl ┆ chunk_tex ┆ entities  ┆ chunk_id  │\n",
       "│ ---        ┆ ---        ┆ ber        ┆ ---       ┆ e         ┆ t         ┆ ---       ┆ ---       │\n",
       "│ str        ┆ str        ┆ ---        ┆ date      ┆ ---       ┆ ---       ┆ list[list ┆ str       │\n",
       "│            ┆            ┆ str        ┆           ┆ str       ┆ str       ┆ [str]]    ┆           │\n",
       "╞════════════╪════════════╪════════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ https://ww ┆ Costco     ┆ Season 13, ┆ 2023-08-2 ┆ The       ┆ I don't   ┆ [[\"Charli ┆ 9a2f203c- │\n",
       "│ w.acquired ┆            ┆ Episode 2  ┆ 0         ┆ Complete  ┆ think I   ┆ eMunger   ┆ f18d-4f1b │\n",
       "│ .fm/episod ┆            ┆            ┆           ┆ History & ┆ have ever ┆ ?\",       ┆ -965d-1be │\n",
       "│ …          ┆            ┆            ┆           ┆ Strateg…  ┆ been…     ┆ \"PER\"],   ┆ d0e…      │\n",
       "│            ┆            ┆            ┆           ┆           ┆           ┆ […        ┆           │\n",
       "│ https://ww ┆ Costco     ┆ Season 13, ┆ 2023-08-2 ┆ The       ┆ But       ┆ [[\"costco ┆ 87c6fd73- │\n",
       "│ w.acquired ┆            ┆ Episode 2  ┆ 0         ┆ Complete  ┆ unlike    ┆ \",        ┆ b811-423f │\n",
       "│ .fm/episod ┆            ┆            ┆           ┆ History & ┆ Costco    ┆ \"ORG\"],   ┆ -a25b-9a0 │\n",
       "│ …          ┆            ┆            ┆           ┆ Strateg…  ┆ today,    ┆ [\"Fedco\", ┆ a53…      │\n",
       "│            ┆            ┆            ┆           ┆           ┆ they …    ┆ …         ┆           │\n",
       "│ https://ww ┆ Costco     ┆ Season 13, ┆ 2023-08-2 ┆ The       ┆ Jim       ┆ [[\"Jim\",  ┆ ba860315- │\n",
       "│ w.acquired ┆            ┆ Episode 2  ┆ 0         ┆ Complete  ┆ started   ┆ \"PER\"],   ┆ b8c4-4ee2 │\n",
       "│ .fm/episod ┆            ┆            ┆           ┆ History & ┆ as a      ┆ [\"CraigJe ┆ -9bdc-95d │\n",
       "│ …          ┆            ┆            ┆           ┆ Strateg…  ┆ grocery   ┆ line…     ┆ 2a1…      │\n",
       "│            ┆            ┆            ┆           ┆           ┆ bagge…    ┆           ┆           │\n",
       "│ https://ww ┆ Costco     ┆ Season 13, ┆ 2023-08-2 ┆ The       ┆ And then  ┆ [[\"SanDie ┆ 19b6d3ed- │\n",
       "│ w.acquired ┆            ┆ Episode 2  ┆ 0         ┆ Complete  ┆ they have ┆ go\",      ┆ 55a6-4424 │\n",
       "│ .fm/episod ┆            ┆            ┆           ┆ History & ┆ the       ┆ \"LOC\"],   ┆ -bdb6-781 │\n",
       "│ …          ┆            ┆            ┆           ┆ Strateg…  ┆ greates…  ┆ [\"SanDie… ┆ 004…      │\n",
       "│ https://ww ┆ Costco     ┆ Season 13, ┆ 2023-08-2 ┆ The       ┆ In 1982,  ┆ [[\"NASDAQ ┆ 46581ec4- │\n",
       "│ w.acquired ┆            ┆ Episode 2  ┆ 0         ┆ Complete  ┆ they do   ┆ \",        ┆ ff10-42e9 │\n",
       "│ .fm/episod ┆            ┆            ┆           ┆ History & ┆ ultimatel ┆ \"MISC\"],  ┆ -b104-ee0 │\n",
       "│ …          ┆            ┆            ┆           ┆ Strateg…  ┆ y li…     ┆ [\"sol\",   ┆ 92c…      │\n",
       "│            ┆            ┆            ┆           ┆           ┆           ┆ \"…        ┆           │\n",
       "│ …          ┆ …          ┆ …          ┆ …         ┆ …         ┆ …         ┆ …         ┆ …         │\n",
       "│ https://ww ┆ Special‚   ┆ Season 1,  ┆ 2016-08-2 ┆ Related   ┆ This      ┆ [[\"Profit ┆ ae6a1ceb- │\n",
       "│ w.acquired ┆ An         ┆ Episode 18 ┆ 2         ┆ Episodes  ┆ person    ┆ FromThe\", ┆ bc15-4219 │\n",
       "│ .fm/episod ┆ Acquirer's ┆            ┆           ┆           ┆ who's     ┆ \"MISC\"],  ┆ -a11d-446 │\n",
       "│ …          ┆ View in…   ┆            ┆           ┆           ┆ been      ┆ [\"…       ┆ 99b…      │\n",
       "│            ┆            ┆            ┆           ┆           ┆ their r…  ┆           ┆           │\n",
       "│ https://ww ┆ Jet        ┆ Season 1,  ┆ 2016-08-2 ┆ Related   ┆ I'm here  ┆ [[\"Adobe\" ┆ 5852936f- │\n",
       "│ w.acquired ┆            ┆ Episode 19 ┆ 9         ┆ Episodes  ┆ at Adobe  ┆ , \"ORG\"], ┆ 2872-4abd │\n",
       "│ .fm/episod ┆            ┆            ┆           ┆           ┆ so feel   ┆ [\"Barada@ ┆ -81a6-978 │\n",
       "│ …          ┆            ┆            ┆           ┆           ┆ free…     ┆ Ad…       ┆ 0c6…      │\n",
       "│ https://ww ┆ Jet        ┆ Season 1,  ┆ 2016-08-2 ┆ Related   ┆ Well,     ┆ [[\"jet\",  ┆ 7391fc5e- │\n",
       "│ w.acquired ┆            ┆ Episode 19 ┆ 9         ┆ Episodes  ┆ that was  ┆ \"ORG\"],   ┆ 47b5-4a41 │\n",
       "│ .fm/episod ┆            ┆            ┆           ┆           ┆ what I    ┆ [\"jet\",   ┆ -b462-6e8 │\n",
       "│ …          ┆            ┆            ┆           ┆           ┆ was goin… ┆ \"ORG\"…    ┆ 532…      │\n",
       "│ https://ww ┆ Jet        ┆ Season 1,  ┆ 2016-08-2 ┆ Related   ┆ Boy, that ┆ [[\"jet\",  ┆ 8b6c4771- │\n",
       "│ w.acquired ┆            ┆ Episode 19 ┆ 9         ┆ Episodes  ┆ doesn't   ┆ \"ORG\"],   ┆ 790f-44c8 │\n",
       "│ .fm/episod ┆            ┆            ┆           ┆           ┆ sound     ┆ [\"Walmart ┆ -9921-b9b │\n",
       "│ …          ┆            ┆            ┆           ┆           ┆ like W…   ┆ \", \"…     ┆ 387…      │\n",
       "│ https://ww ┆ Jet        ┆ Season 1,  ┆ 2016-08-2 ┆ Related   ┆ They've   ┆ [[\"jet\",  ┆ 2bb84e43- │\n",
       "│ w.acquired ┆            ┆ Episode 19 ┆ 9         ┆ Episodes  ┆ created   ┆ \"ORG\"],   ┆ f312-41d0 │\n",
       "│ .fm/episod ┆            ┆            ┆           ┆           ┆ this      ┆ [\"jet\",   ┆ -85cd-172 │\n",
       "│ …          ┆            ┆            ┆           ┆           ┆ totally   ┆ \"ORG\"…    ┆ 265…      │\n",
       "│            ┆            ┆            ┆           ┆           ┆ d…        ┆           ┆           │\n",
       "└────────────┴────────────┴────────────┴───────────┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the dataframe form the processing pipeline\n",
    "chunks_df = pl.read_parquet(\"/Users/borja/Documents/Somniumrema/projects/genai/grag/pipeline_outcomes/chunks_df.parquet\")\n",
    "\n",
    "# Select only the columns needed\n",
    "chunks_df = chunks_df[['post_url', 'post_title', 'series_number', 'blog_date', 'blog_title', 'chunk_text', 'entities']]\n",
    "\n",
    "# Add a 'chunk_id' column to the DataFrame with UUIDs (if not already present)\n",
    "if \"chunk_id\" not in chunks_df.columns:\n",
    "    chunks_df = chunks_df.with_columns([\n",
    "        pl.Series(\"chunk_id\", [str(uuid.uuid4()) for _ in range(len(chunks_df))])\n",
    "    ])\n",
    "# Show the first five\n",
    "chunks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>post_url</th><th>post_title</th><th>series_number</th><th>blog_date</th><th>blog_title</th><th>chunk_text</th><th>entities</th><th>chunk_id</th></tr><tr><td>str</td><td>str</td><td>str</td><td>date</td><td>str</td><td>str</td><td>list[list[str]]</td><td>str</td></tr></thead><tbody><tr><td>&quot;https://www.acquired.fm/episod…</td><td>&quot;Airbnb&quot;</td><td>&quot;Season 7, Episode 8&quot;</td><td>2020-12-10</td><td>&quot;‍&quot;</td><td>&quot;Similarly for gifts, it&#x27;s a li…</td><td>[[&quot;lpshow&quot;, &quot;ORG&quot;], [&quot;BenGilbert&quot;, &quot;PER&quot;], … [&quot;DoorDash&quot;, &quot;ORG&quot;]]</td><td>&quot;1f55e38f-468a-457e-b539-d84aa7…</td></tr><tr><td>&quot;https://www.acquired.fm/episod…</td><td>&quot;Airbnb&quot;</td><td>&quot;Season 7, Episode 8&quot;</td><td>2020-12-10</td><td>&quot;‍&quot;</td><td>&quot;But I remember looking at hote…</td><td>[[&quot;WWDC&quot;, &quot;MISC&quot;], [&quot;&quot;, &quot;MISC&quot;], … [&quot;SanFrancisco&quot;, &quot;LOC&quot;]]</td><td>&quot;fff320b7-171e-414a-b4b6-fa0c64…</td></tr><tr><td>&quot;https://www.acquired.fm/episod…</td><td>&quot;Airbnb&quot;</td><td>&quot;Season 7, Episode 8&quot;</td><td>2020-12-10</td><td>&quot;‍&quot;</td><td>&quot;They&#x27;re still trying to basica…</td><td>[[&quot;cheerio&quot;, &quot;MISC&quot;], [&quot;y&quot;, &quot;ORG&quot;], … [&quot;JeffBezos&quot;, &quot;PER&quot;]]</td><td>&quot;c72d72b5-4194-4102-a893-c08f9f…</td></tr><tr><td>&quot;https://www.acquired.fm/episod…</td><td>&quot;Airbnb&quot;</td><td>&quot;Season 7, Episode 8&quot;</td><td>2020-12-10</td><td>&quot;‍&quot;</td><td>&quot;For something that seemed like…</td><td>[[&quot;Sequoia&quot;, &quot;ORG&quot;], [&quot;Airbnb&quot;, &quot;ORG&quot;], … [&quot;Facebook&quot;, &quot;MISC&quot;]]</td><td>&quot;5cc7bdb9-6783-41c9-8b81-128d2c…</td></tr><tr><td>&quot;https://www.acquired.fm/episod…</td><td>&quot;Airbnb&quot;</td><td>&quot;Season 7, Episode 8&quot;</td><td>2020-12-10</td><td>&quot;‍&quot;</td><td>&quot;Never heard of a startup winni…</td><td>[[&quot;NobelPeacePrize ,&quot;, &quot;MISC&quot;], [&quot;UpstartstoBrad&quot;, &quot;MISC&quot;], … [&quot;Samwer&quot;, &quot;PER&quot;]]</td><td>&quot;eb1a4710-3049-4d5e-be5b-47b62c…</td></tr><tr><td>&quot;https://www.acquired.fm/episod…</td><td>&quot;Airbnb&quot;</td><td>&quot;Season 7, Episode 8&quot;</td><td>2020-12-10</td><td>&quot;‍&quot;</td><td>&quot;Which we&#x27;ve alluded to in our …</td><td>[[&quot;ipo&quot;, &quot;MISC&quot;]]</td><td>&quot;7c97989d-97b1-4a26-b8c6-4e03e5…</td></tr><tr><td>&quot;https://www.acquired.fm/episod…</td><td>&quot;Airbnb&quot;</td><td>&quot;Season 7, Episode 8&quot;</td><td>2020-12-10</td><td>&quot;‍&quot;</td><td>&quot;We do have some more nuggets h…</td><td>[[&quot;s1&quot;, &quot;MISC&quot;], [&quot;bamboo&quot;, &quot;ORG&quot;], … [&quot;BrianChesky&quot;, &quot;PER&quot;]]</td><td>&quot;fad272ff-c099-4b06-a999-7fb067…</td></tr><tr><td>&quot;https://www.acquired.fm/episod…</td><td>&quot;Airbnb&quot;</td><td>&quot;Season 7, Episode 8&quot;</td><td>2020-12-10</td><td>&quot;‍&quot;</td><td>&quot;All markets are supply and dem…</td><td>[[&quot;Airbnb&quot;, &quot;ORG&quot;], [&quot;Airbnb&quot;, &quot;ORG&quot;], … [&quot;Airbnb&quot;, &quot;ORG&quot;]]</td><td>&quot;4248dafc-a16d-45e2-8bce-e8b2c2…</td></tr><tr><td>&quot;https://www.acquired.fm/episod…</td><td>&quot;Airbnb&quot;</td><td>&quot;Season 7, Episode 8&quot;</td><td>2020-12-10</td><td>&quot;‍&quot;</td><td>&quot;For consumers, it&#x27;s very easy …</td><td>[[&quot;uber&quot;, &quot;MISC&quot;], [&quot;Airbnb&quot;, &quot;MISC&quot;], … [&quot;Airbnb&quot;, &quot;ORG&quot;]]</td><td>&quot;bc907952-0dcb-40f2-9cc9-672b33…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 8)\n",
       "┌────────────┬────────────┬────────────┬───────────┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ post_url   ┆ post_title ┆ series_num ┆ blog_date ┆ blog_titl ┆ chunk_tex ┆ entities  ┆ chunk_id  │\n",
       "│ ---        ┆ ---        ┆ ber        ┆ ---       ┆ e         ┆ t         ┆ ---       ┆ ---       │\n",
       "│ str        ┆ str        ┆ ---        ┆ date      ┆ ---       ┆ ---       ┆ list[list ┆ str       │\n",
       "│            ┆            ┆ str        ┆           ┆ str       ┆ str       ┆ [str]]    ┆           │\n",
       "╞════════════╪════════════╪════════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ https://ww ┆ Airbnb     ┆ Season 7,  ┆ 2020-12-1 ┆ ‍          ┆ Similarly ┆ [[\"lpshow ┆ 1f55e38f- │\n",
       "│ w.acquired ┆            ┆ Episode 8  ┆ 0         ┆           ┆ for       ┆ \",        ┆ 468a-457e │\n",
       "│ .fm/episod ┆            ┆            ┆           ┆           ┆ gifts,    ┆ \"ORG\"],   ┆ -b539-d84 │\n",
       "│ …          ┆            ┆            ┆           ┆           ┆ it's a    ┆ [\"BenGilb ┆ aa7…      │\n",
       "│            ┆            ┆            ┆           ┆           ┆ li…       ┆ e…        ┆           │\n",
       "│ https://ww ┆ Airbnb     ┆ Season 7,  ┆ 2020-12-1 ┆ ‍          ┆ But I     ┆ [[\"WWDC\", ┆ fff320b7- │\n",
       "│ w.acquired ┆            ┆ Episode 8  ┆ 0         ┆           ┆ remember  ┆ \"MISC\"],  ┆ 171e-414a │\n",
       "│ .fm/episod ┆            ┆            ┆           ┆           ┆ looking   ┆ [\"\",      ┆ -b4b6-fa0 │\n",
       "│ …          ┆            ┆            ┆           ┆           ┆ at hote…  ┆ \"MISC\"…   ┆ c64…      │\n",
       "│ https://ww ┆ Airbnb     ┆ Season 7,  ┆ 2020-12-1 ┆ ‍          ┆ They're   ┆ [[\"cheeri ┆ c72d72b5- │\n",
       "│ w.acquired ┆            ┆ Episode 8  ┆ 0         ┆           ┆ still     ┆ o\",       ┆ 4194-4102 │\n",
       "│ .fm/episod ┆            ┆            ┆           ┆           ┆ trying to ┆ \"MISC\"],  ┆ -a893-c08 │\n",
       "│ …          ┆            ┆            ┆           ┆           ┆ basica…   ┆ [\"y\", \"O… ┆ f9f…      │\n",
       "│ https://ww ┆ Airbnb     ┆ Season 7,  ┆ 2020-12-1 ┆ ‍          ┆ For       ┆ [[\"Sequoi ┆ 5cc7bdb9- │\n",
       "│ w.acquired ┆            ┆ Episode 8  ┆ 0         ┆           ┆ something ┆ a\",       ┆ 6783-41c9 │\n",
       "│ .fm/episod ┆            ┆            ┆           ┆           ┆ that      ┆ \"ORG\"],   ┆ -8b81-128 │\n",
       "│ …          ┆            ┆            ┆           ┆           ┆ seemed    ┆ [\"Airbnb\" ┆ d2c…      │\n",
       "│            ┆            ┆            ┆           ┆           ┆ like…     ┆ …         ┆           │\n",
       "│ https://ww ┆ Airbnb     ┆ Season 7,  ┆ 2020-12-1 ┆ ‍          ┆ Never     ┆ [[\"NobelP ┆ eb1a4710- │\n",
       "│ w.acquired ┆            ┆ Episode 8  ┆ 0         ┆           ┆ heard of  ┆ eacePrize ┆ 3049-4d5e │\n",
       "│ .fm/episod ┆            ┆            ┆           ┆           ┆ a startup ┆ ,\",       ┆ -be5b-47b │\n",
       "│ …          ┆            ┆            ┆           ┆           ┆ winni…    ┆ \"MISC\"]…  ┆ 62c…      │\n",
       "│ https://ww ┆ Airbnb     ┆ Season 7,  ┆ 2020-12-1 ┆ ‍          ┆ Which     ┆ [[\"ipo\",  ┆ 7c97989d- │\n",
       "│ w.acquired ┆            ┆ Episode 8  ┆ 0         ┆           ┆ we've     ┆ \"MISC\"]]  ┆ 97b1-4a26 │\n",
       "│ .fm/episod ┆            ┆            ┆           ┆           ┆ alluded   ┆           ┆ -b8c6-4e0 │\n",
       "│ …          ┆            ┆            ┆           ┆           ┆ to in our ┆           ┆ 3e5…      │\n",
       "│            ┆            ┆            ┆           ┆           ┆ …         ┆           ┆           │\n",
       "│ https://ww ┆ Airbnb     ┆ Season 7,  ┆ 2020-12-1 ┆ ‍          ┆ We do     ┆ [[\"s1\",   ┆ fad272ff- │\n",
       "│ w.acquired ┆            ┆ Episode 8  ┆ 0         ┆           ┆ have some ┆ \"MISC\"],  ┆ c099-4b06 │\n",
       "│ .fm/episod ┆            ┆            ┆           ┆           ┆ more      ┆ [\"bamboo\" ┆ -a999-7fb │\n",
       "│ …          ┆            ┆            ┆           ┆           ┆ nuggets   ┆ , \"O…     ┆ 067…      │\n",
       "│            ┆            ┆            ┆           ┆           ┆ h…        ┆           ┆           │\n",
       "│ https://ww ┆ Airbnb     ┆ Season 7,  ┆ 2020-12-1 ┆ ‍          ┆ All       ┆ [[\"Airbnb ┆ 4248dafc- │\n",
       "│ w.acquired ┆            ┆ Episode 8  ┆ 0         ┆           ┆ markets   ┆ \",        ┆ a16d-45e2 │\n",
       "│ .fm/episod ┆            ┆            ┆           ┆           ┆ are       ┆ \"ORG\"],   ┆ -8bce-e8b │\n",
       "│ …          ┆            ┆            ┆           ┆           ┆ supply    ┆ [\"Airbnb\" ┆ 2c2…      │\n",
       "│            ┆            ┆            ┆           ┆           ┆ and dem…  ┆ ,…        ┆           │\n",
       "│ https://ww ┆ Airbnb     ┆ Season 7,  ┆ 2020-12-1 ┆ ‍          ┆ For consu ┆ [[\"uber\", ┆ bc907952- │\n",
       "│ w.acquired ┆            ┆ Episode 8  ┆ 0         ┆           ┆ mers,     ┆ \"MISC\"],  ┆ 0dcb-40f2 │\n",
       "│ .fm/episod ┆            ┆            ┆           ┆           ┆ it's very ┆ [\"Airbnb\" ┆ -9cc9-672 │\n",
       "│ …          ┆            ┆            ┆           ┆           ┆ easy …    ┆ , …       ┆ b33…      │\n",
       "└────────────┴────────────┴────────────┴───────────┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks_df.filter(pl.col(\"post_title\") == \"Airbnb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the full-text index\n",
    "# with driver.session() as session:\n",
    "#     session.run(\n",
    "#         \"CREATE FULLTEXT INDEX chunk_fulltext_index FOR (c:Chunk) ON EACH [c.text] OPTIONS { indexConfig: { `fulltext.analyzer`: 'standard' } };\"\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for bulk upload with DISTINCT podcast nodes\n",
    "podcast_nodes = []\n",
    "chunk_nodes = []\n",
    "belongs_to_rels = []\n",
    "entity_nodes = []\n",
    "mentions_rels = []\n",
    "\n",
    "# Create sets to keep track of unique nodes and relationships\n",
    "unique_podcast_nodes = set()\n",
    "unique_chunk_nodes = set()\n",
    "unique_belongs_to_rels = set()\n",
    "unique_entity_nodes = set()\n",
    "unique_mentions_rels = set()\n",
    "\n",
    "for row in chunks_df.iter_rows(named=True):\n",
    "    # --- Podcast Nodes ---\n",
    "    \n",
    "    # Create a key for the podcast based on its identifying attributes\n",
    "    podcast_key = (row['post_url'], row['post_title'])  # Use a tuple of relevant attributes\n",
    "\n",
    "    if podcast_key not in unique_podcast_nodes:\n",
    "        podcast_node = {\n",
    "            \"podcast_id\": str(uuid.uuid4()),\n",
    "            \"post_url\": row['post_url'],\n",
    "            \"post_title\": row['post_title'],\n",
    "            \"blog_date\": row['blog_date'],\n",
    "            \"blog_title\": row['blog_title'],\n",
    "            \"series_number\": row['series_number']\n",
    "        }\n",
    "        podcast_nodes.append(podcast_node)\n",
    "        unique_podcast_nodes.add(podcast_key)\n",
    "\n",
    "    # --- Chunk Nodes ---\n",
    "    chunk_node = {\n",
    "        \"chunk_id\": row['chunk_id'],\n",
    "        \"text\": row['chunk_text']\n",
    "    }\n",
    "    if tuple(chunk_node.items()) not in unique_chunk_nodes:\n",
    "        chunk_nodes.append(chunk_node)\n",
    "        unique_chunk_nodes.add(tuple(chunk_node.items()))\n",
    "\n",
    "    # --- BELONGS_TO Relationships ---\n",
    "    belongs_to_rel = {\n",
    "        \"chunk_id\": row['chunk_id'],\n",
    "        \"podcast_id\": podcast_node['podcast_id']  # Use the podcast_id from the podcast_node\n",
    "    }\n",
    "    if tuple(belongs_to_rel.items()) not in unique_belongs_to_rels:\n",
    "        belongs_to_rels.append(belongs_to_rel)\n",
    "        unique_belongs_to_rels.add(tuple(belongs_to_rel.items()))\n",
    "\n",
    "    # --- Entity Nodes and MENTIONS Relationships ---\n",
    "    for entity, label in row['entities']:\n",
    "        entity_node = {\n",
    "            \"name\": entity,\n",
    "            \"label\": label\n",
    "        }\n",
    "        if tuple(entity_node.items()) not in unique_entity_nodes:\n",
    "            entity_nodes.append(entity_node)\n",
    "            unique_entity_nodes.add(tuple(entity_node.items()))\n",
    "\n",
    "        mentions_rel = {\n",
    "            \"chunk_id\": row['chunk_id'],\n",
    "            \"entity_name\": entity,\n",
    "            \"entity_label\": label\n",
    "        }\n",
    "        if tuple(mentions_rel.items()) not in unique_mentions_rels:\n",
    "            mentions_rels.append(mentions_rel)\n",
    "            unique_mentions_rels.add(tuple(mentions_rel.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199, 1304, 1304, 4579, 9365)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of nodes and relationships\n",
    "len(podcast_nodes), len(chunk_nodes), len(belongs_to_rels), len(entity_nodes), len(mentions_rels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned and Deduplicated Nodes:\n",
      "{'name': 'North America', 'label': None}\n",
      "{'name': 'North American', 'label': None}\n",
      "{'name': 'Invest Like The', 'label': None}\n",
      "{'name': 'Invest Likethe', 'label': None}\n",
      "{'name': 'Charlie Munger', 'label': None}\n",
      "{'name': 'Charliemunger', 'label': None}\n",
      "{'name': 'Virgin Galactic', 'label': None}\n",
      "{'name': 'Virgingalactic', 'label': None}\n",
      "{'name': 'Pitch Book', 'label': None}\n",
      "{'name': 'Pitch Books', 'label': None}\n",
      "{'name': 'Foursquare', 'label': None}\n",
      "{'name': 'Four Square', 'label': None}\n",
      "{'name': 'David Rosenthal', 'label': None}\n",
      "{'name': 'Davidrosenthal', 'label': None}\n",
      "{'name': 'Squarespace', 'label': None}\n",
      "{'name': 'Square Space', 'label': None}\n",
      "{'name': 'Siliconvalley', 'label': None}\n",
      "{'name': 'Silicon Valley', 'label': None}\n",
      "{'name': 'Blizzardentertainment', 'label': None}\n",
      "{'name': 'Blizzard Entertainment', 'label': None}\n",
      "{'name': 'Donvalentine', 'label': None}\n",
      "{'name': 'Don Valentine', 'label': None}\n",
      "{'name': 'Gearsof Wars', 'label': None}\n",
      "{'name': 'Gearsof War', 'label': None}\n",
      "{'name': 'Buffett Partnership', 'label': None}\n",
      "{'name': 'Buffett Partnerships', 'label': None}\n",
      "{'name': 'Mark Zuckerberg', 'label': None}\n",
      "{'name': 'Marck Zuckerberg', 'label': None}\n",
      "{'name': 'Vision Fund', 'label': None}\n",
      "{'name': 'Vision Fund1', 'label': None}\n",
      "{'name': 'Java Script', 'label': None}\n",
      "{'name': 'Javascript', 'label': None}\n",
      "{'name': 'Buildhopper', 'label': None}\n",
      "{'name': 'Build Hopper', 'label': None}\n",
      "{'name': 'Skunk Works', 'label': None}\n",
      "{'name': 'Skunkworks', 'label': None}\n",
      "{'name': 'Taylorbarada', 'label': None}\n",
      "{'name': 'Taylor Barada', 'label': None}\n",
      "{'name': 'Play Station', 'label': None}\n",
      "{'name': 'Play Station2', 'label': None}\n",
      "{'name': 'Playstation', 'label': None}\n",
      "{'name': 'The Soprano', 'label': None}\n",
      "{'name': 'The Sopranos', 'label': None}\n",
      "{'name': 'Grand Theft Auto', 'label': None}\n",
      "{'name': 'Grand Theft Auto5', 'label': None}\n",
      "{'name': 'Raspberry Pi', 'label': None}\n",
      "{'name': 'Raspberry Pis', 'label': None}\n",
      "{'name': 'Google Docs', 'label': None}\n",
      "{'name': 'Google Doc', 'label': None}\n",
      "{'name': 'Silicon Valley', 'label': None}\n",
      "{'name': 'Silicon Alley', 'label': None}\n",
      "\n",
      "Identified Duplicates:\n",
      "Canonical Name: North America\n",
      "  - Duplicate: North American\n",
      "Canonical Name: Invest Like The\n",
      "  - Duplicate: Invest Likethe\n",
      "Canonical Name: Charlie Munger\n",
      "  - Duplicate: Charliemunger\n",
      "Canonical Name: Virgin Galactic\n",
      "  - Duplicate: Virgingalactic\n",
      "Canonical Name: Pitch Book\n",
      "  - Duplicate: Pitch Books\n",
      "Canonical Name: Foursquare\n",
      "  - Duplicate: Four Square\n",
      "Canonical Name: David Rosenthal\n",
      "  - Duplicate: Davidrosenthal\n",
      "Canonical Name: Squarespace\n",
      "  - Duplicate: Square Space\n",
      "Canonical Name: Siliconvalley\n",
      "  - Duplicate: Silicon Valley\n",
      "Canonical Name: Blizzardentertainment\n",
      "  - Duplicate: Blizzard Entertainment\n",
      "Canonical Name: Donvalentine\n",
      "  - Duplicate: Don Valentine\n",
      "Canonical Name: Gearsof Wars\n",
      "  - Duplicate: Gearsof War\n",
      "Canonical Name: Buffett Partnership\n",
      "  - Duplicate: Buffett Partnerships\n",
      "Canonical Name: Mark Zuckerberg\n",
      "  - Duplicate: Marck Zuckerberg\n",
      "Canonical Name: Vision Fund\n",
      "  - Duplicate: Vision Fund1\n",
      "Canonical Name: Java Script\n",
      "  - Duplicate: Javascript\n",
      "Canonical Name: Buildhopper\n",
      "  - Duplicate: Build Hopper\n",
      "Canonical Name: Skunk Works\n",
      "  - Duplicate: Skunkworks\n",
      "Canonical Name: Taylorbarada\n",
      "  - Duplicate: Taylor Barada\n",
      "Canonical Name: Play Station\n",
      "  - Duplicate: Play Station2\n",
      "  - Duplicate: Playstation\n",
      "Canonical Name: The Soprano\n",
      "  - Duplicate: The Sopranos\n",
      "Canonical Name: Grand Theft Auto\n",
      "  - Duplicate: Grand Theft Auto5\n",
      "Canonical Name: Raspberry Pi\n",
      "  - Duplicate: Raspberry Pis\n",
      "Canonical Name: Google Docs\n",
      "  - Duplicate: Google Doc\n",
      "Canonical Name: Silicon Valley\n",
      "  - Duplicate: Silicon Alley\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from rapidfuzz import fuzz\n",
    "from collections import defaultdict\n",
    "import polars as pl\n",
    "\n",
    "def clean_node_name(name):\n",
    "    \"\"\"\n",
    "    Cleans the node name by:\n",
    "    - Removing extraneous punctuation\n",
    "    - Adding spaces before uppercase letters for better readability\n",
    "    - Standardizing to title case\n",
    "    \"\"\"\n",
    "    if not isinstance(name, str):\n",
    "        return name  # Return as is if not a string\n",
    "    \n",
    "    name = re.sub(r'[^\\w\\s]', '', name)  # Remove punctuation\n",
    "    name = re.sub(r'(?<!^)(?=[A-Z])', ' ', name)  # Space before uppercase\n",
    "    name = name.title()  # Title case\n",
    "    return ' '.join(name.split())  # Remove extra spaces\n",
    "\n",
    "def standardize_nodes(nodes, name_column=\"name\"):\n",
    "    \"\"\"\n",
    "    Applies cleaning to all node names and adds standardized name fields.\n",
    "    \"\"\"\n",
    "    df = pl.DataFrame(nodes)\n",
    "    \n",
    "    # Clean and standardize node names\n",
    "    df = df.with_columns([\n",
    "        pl.col(name_column).map_elements(clean_node_name, return_dtype=pl.Utf8).alias(\"cleaned_name\"),\n",
    "        pl.col(name_column).map_elements(lambda x: clean_node_name(x).lower() if isinstance(x, str) else x, return_dtype=pl.Utf8).alias(\"cleaned_name_lower\")\n",
    "    ])\n",
    "    return df\n",
    "\n",
    "def identify_duplicates(df, similarity_threshold=90):\n",
    "    \"\"\"\n",
    "    Identifies duplicates based on name similarity.\n",
    "    \"\"\"\n",
    "    duplicates = defaultdict(list)\n",
    "    unique_names = df[\"cleaned_name\"].unique().to_list()\n",
    "    \n",
    "    for i, name in enumerate(unique_names):\n",
    "        for other_name in unique_names[i + 1:]:\n",
    "            similarity = fuzz.ratio(name.lower(), other_name.lower())\n",
    "            if similarity >= similarity_threshold:\n",
    "                duplicates[name].append(other_name)\n",
    "    return duplicates\n",
    "\n",
    "def merge_duplicates(df, duplicates):\n",
    "    \"\"\"\n",
    "    Merges duplicate entries by selecting a canonical name and updating labels.\n",
    "    \"\"\"\n",
    "    merged_entries = []\n",
    "    for canonical, dup_list in duplicates.items():\n",
    "        labels = df.filter(pl.col(\"cleaned_name\") == canonical)[\"label\"].to_list()\n",
    "        most_common_label = max(set(labels), key=labels.count) if labels else 'MISC'\n",
    "        merged_entries.append({'name': canonical, 'label': most_common_label})\n",
    "        \n",
    "        for dup in dup_list:\n",
    "            dup_labels = df.filter(pl.col(\"cleaned_name\") == dup)[\"label\"].to_list()\n",
    "            dup_most_common_label = max(set(dup_labels), key=dup_labels.count) if dup_labels else 'MISC'\n",
    "            merged_entries.append({'name': dup, 'label': dup_most_common_label})\n",
    "    \n",
    "    merged_df = pl.DataFrame(merged_entries)\n",
    "    return merged_df\n",
    "\n",
    "def correct_labels(merged_df):\n",
    "    \"\"\"\n",
    "    Corrects misclassified labels based on business rules.\n",
    "    \"\"\"\n",
    "    label_corrections = {\n",
    "        'Sol': 'PER',\n",
    "    }\n",
    "    \n",
    "    merged_df = merged_df.with_columns(\n",
    "        pl.col(\"label\").map_elements(\n",
    "            lambda label, name: label_corrections.get(name.lower(), label) \n",
    "            if name.lower() in label_corrections else label, \n",
    "            return_dtype=pl.Utf8\n",
    "        )\n",
    "    )\n",
    "    return merged_df\n",
    "\n",
    "def clean_and_deduplicate(nodes, similarity_threshold=90):\n",
    "    df = standardize_nodes(nodes)\n",
    "    duplicates = identify_duplicates(df, similarity_threshold=similarity_threshold)\n",
    "    merged_df = merge_duplicates(df, duplicates)\n",
    "    \n",
    "    # Ensure merged_df has the necessary columns\n",
    "    if \"name\" not in merged_df.columns:\n",
    "        merged_df = merged_df.with_columns(pl.col(\"cleaned_name\").alias(\"name\"))\n",
    "    if \"label\" not in merged_df.columns:\n",
    "        merged_df = merged_df.with_columns(pl.lit(\"MISC\").alias(\"label\"))\n",
    "    \n",
    "    corrected_df = correct_labels(merged_df)\n",
    "    return corrected_df.select([\"name\", \"label\"]).to_dicts(), duplicates\n",
    "\n",
    "# Execution\n",
    "cleaned_nodes, duplicates_info = clean_and_deduplicate(entity_nodes, similarity_threshold=95)\n",
    "\n",
    "# Output cleaned nodes and duplicates\n",
    "print(\"Cleaned and Deduplicated Nodes:\")\n",
    "for node in cleaned_nodes:\n",
    "    print(node)\n",
    "\n",
    "if duplicates_info:\n",
    "    print(\"\\nIdentified Duplicates:\")\n",
    "    for canonical, dup_list in duplicates_info.items():\n",
    "        print(f\"Canonical Name: {canonical}\")\n",
    "        for dup in dup_list:\n",
    "            print(f\"  - Duplicate: {dup}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Bulk upload nodes and relationships\n",
    "# with driver.session() as session:\n",
    "#     # --- Podcast Nodes ---\n",
    "#     for i in tqdm(range(0, len(podcast_nodes), 1000), desc=\"Creating Podcast Nodes\"):\n",
    "#         batch = podcast_nodes[i:i + 1000]\n",
    "#         session.run(\n",
    "#             \"\"\"\n",
    "#             UNWIND $podcast_nodes AS podcast\n",
    "#             MERGE (p:Podcast {podcast_id: podcast.podcast_id})\n",
    "#             SET p.post_url = podcast.post_url, \n",
    "#                 p.post_title = podcast.post_title,\n",
    "#                 p.blog_date = podcast.blog_date, \n",
    "#                 p.blog_title = podcast.blog_title,\n",
    "#                 p.series_number = podcast.series_number\n",
    "#             \"\"\",\n",
    "#             podcast_nodes=batch\n",
    "#         )\n",
    "\n",
    "#     # --- Chunk Nodes ---\n",
    "#     for i in tqdm(range(0, len(chunk_nodes), 1000), desc=\"Creating Chunk Nodes\"):\n",
    "#         batch = chunk_nodes[i:i + 1000]\n",
    "#         session.run(\n",
    "#             \"\"\"\n",
    "#             UNWIND $chunk_nodes AS chunk\n",
    "#             CREATE (c:Chunk {chunk_id: chunk.chunk_id, text: chunk.text})\n",
    "#             \"\"\",\n",
    "#             chunk_nodes=batch\n",
    "#         )\n",
    "\n",
    "#     # --- BELONGS_TO Relationships ---\n",
    "#     for i in tqdm(range(0, len(belongs_to_rels), 1000), desc=\"Creating BELONGS_TO Relationships\"):\n",
    "#         batch = belongs_to_rels[i:i + 1000]\n",
    "#         session.run(\n",
    "#             \"\"\"\n",
    "#             UNWIND $belongs_to_rels AS rel\n",
    "#             MATCH (c:Chunk {chunk_id: rel.chunk_id})\n",
    "#             MATCH (p:Podcast {podcast_id: rel.podcast_id})\n",
    "#             CREATE (c)-[:BELONGS_TO]->(p)\n",
    "#             \"\"\",\n",
    "#             belongs_to_rels=batch\n",
    "#         )\n",
    "\n",
    "#     # --- Entity Nodes and MENTIONS Relationships ---\n",
    "#     unique_entity_nodes = []\n",
    "#     for entity in entity_nodes:\n",
    "#         if entity not in unique_entity_nodes:\n",
    "#             unique_entity_nodes.append(entity)\n",
    "\n",
    "#     for i in tqdm(range(0, len(unique_entity_nodes), 1000), desc=\"Creating Entity Nodes\"):\n",
    "#         batch = unique_entity_nodes[i:i + 1000]\n",
    "#         session.run(\n",
    "#             \"\"\"\n",
    "#             UNWIND $entity_nodes AS entity\n",
    "#             MERGE (e:Entity {name: entity.name, label: entity.label})  \n",
    "#             \"\"\",\n",
    "#             entity_nodes=batch\n",
    "#         )\n",
    "\n",
    "#     # Create a list to store unique mentions relationships\n",
    "#     unique_mentions_rels = []\n",
    "#     for rel in mentions_rels:\n",
    "#         if rel not in unique_mentions_rels:\n",
    "#             unique_mentions_rels.append(rel)\n",
    "#     for i in tqdm(range(0, len(unique_mentions_rels), 1000), desc=\"Creating MENTIONS Relationships\"):\n",
    "#         batch = unique_mentions_rels[i:i + 1000]\n",
    "#         try:\n",
    "#             session.run(\n",
    "#                 \"\"\"\n",
    "#                 UNWIND $mentions_rels AS rel\n",
    "#                 MATCH (c:Chunk {chunk_id: rel.chunk_id})\n",
    "#                 MATCH (e:Entity {name: rel.entity_name, label: rel.entity_label})  \n",
    "#                 CREATE (c)-[:MENTIONS]->(e)\n",
    "#                 \"\"\",\n",
    "#                 mentions_rels=batch\n",
    "#             )\n",
    "#         except DatabaseError as e:\n",
    "#             if e.code == DatabaseError.Transaction.TransactionCommitFailed:\n",
    "#                 print(f\"Error creating MENTIONS relationships (batch {i // 1000 + 1}): {e.message}\")\n",
    "#                 # Handle the error (e.g., log the error, skip the batch, retry with smaller batches)\n",
    "#             else:\n",
    "#                 raise e  # Raise other types of errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grag-EOKyDehK-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
