{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "\n",
    "from grag.create_graph import (\n",
    "    create_driver, \n",
    "    initialize_embeddings,\n",
    "    initialize_llm,\n",
    "    initialize_vector_store,\n",
    "    create_vector_index,\n",
    "    create_documents_from_df,\n",
    "    create_batches,\n",
    "    delete_all_nodes_and_indexes,\n",
    "    embed_and_add_batch,\n",
    "    qa_pipeline\n",
    ")\n",
    "\n",
    "# Third-party imports\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "import polars as pl\n",
    "from tqdm import tqdm\n",
    "\n",
    "# LangChain imports\n",
    "from langchain.chains import RetrievalQA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "NEO4J_USERNAME = os.getenv(\"NEO4J_USERNAME\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
    "NEO4J_URI = os.getenv(\"NEO4J_URI\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Define max tokens per batch\n",
    "max_tokens_per_batch = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE_VECTOR_INDEX_CYPHER = \"\"\"\n",
    "CREATE VECTOR INDEX vector_index FOR (c:Chunk) ON (c.embedding)\n",
    "OPTIONS {\n",
    "  indexConfig:{\n",
    "    `vector.dimensions`: 1536,\n",
    "    `vector.hnsw.m`: 48,\n",
    "    `vector.hnsw.ef_construction`: 200,\n",
    "    `vector.quantization.enabled`: false,\n",
    "    `vector.similarity_function`: 'cosine'\n",
    "  }\n",
    "};\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "chunk_df = pl.read_parquet(\"/Users/borja/Documents/Somniumrema/projects/genai/grag/pipeline_outcomes/chunks_df.parquet\")\n",
    "\n",
    "# Import questions\n",
    "questions = pl.read_csv(\"/Users/borja/Documents/Somniumrema/projects/genai/grag/data/acquired-qa-evaluation.csv\",\n",
    "                        encoding=\"latin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:grag.create_graph:Neo4j driver created successfully.\n",
      "INFO:grag.create_graph:Embeddings initialized with model: text-embedding-ada-002\n",
      "INFO:grag.create_graph:Language model initialized with model: gpt-3.5-turbo\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:grag.create_graph:Neo4jVector store initialized with index: vector_index\n"
     ]
    }
   ],
   "source": [
    "# Initialize Neo4j driver\n",
    "driver = create_driver(NEO4J_URI, NEO4J_USERNAME, NEO4J_PASSWORD)\n",
    "\n",
    "# Delete all nodes and indexes\n",
    "# delete_all_nodes_and_indexes(driver)\n",
    "\n",
    "# Initialize embeddings\n",
    "embeddings = initialize_embeddings()\n",
    "        \n",
    "# Initialize language model\n",
    "llm = initialize_llm(model_name = \"gpt-3.5-turbo\", temperature = 0)\n",
    "        \n",
    "# Initialize vector store\n",
    "vector_store = initialize_vector_store(\n",
    "    embeddings=embeddings,\n",
    "    uri=NEO4J_URI,\n",
    "    user=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD\n",
    "        )\n",
    "\n",
    "# Initialize the RetrievalQA Chain\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",  # Simple concatenation of retrieved docs into the prompt\n",
    "    retriever=vector_store.as_retriever(search_kwargs={\"k\": 3}),  # Retrieve top 5 relevant documents\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RetrievalQA Chain\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",  # Simple concatenation of retrieved docs into the prompt\n",
    "    retriever=vector_store.as_retriever(search_kwargs={\"k\": 3}),  # Retrieve top 5 relevant documents\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:grag.create_graph:Index 'vector_index' created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create the vector index\n",
    "create_vector_index(driver, CREATE_VECTOR_INDEX_CYPHER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:grag.create_graph:Starting to create Document objects from DataFrame.\n",
      "INFO:grag.create_graph:Created 1304 Document objects.\n",
      "INFO:__main__:Total documents created: 1304\n"
     ]
    }
   ],
   "source": [
    "# Create documents from DataFrame\n",
    "documents = create_documents_from_df(chunk_df)\n",
    "logger.info(f\"Total documents created: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Batches to Process: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:   0%|          | 0/45 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: Successfully added to Neo4jVector.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:   2%|▏         | 1/45 [00:05<04:02,  5.52s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2: Successfully added to Neo4jVector.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:   4%|▍         | 2/45 [00:09<03:29,  4.88s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3: Successfully added to Neo4jVector.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:   7%|▋         | 3/45 [00:14<03:22,  4.81s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4: Successfully added to Neo4jVector.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:   9%|▉         | 4/45 [00:18<03:00,  4.39s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5: Successfully added to Neo4jVector.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  11%|█         | 5/45 [00:22<02:49,  4.23s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6: Successfully added to Neo4jVector.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  13%|█▎        | 6/45 [00:26<02:40,  4.12s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7: Successfully added to Neo4jVector.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  16%|█▌        | 7/45 [00:29<02:29,  3.92s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 8: Successfully added to Neo4jVector.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  18%|█▊        | 8/45 [00:33<02:24,  3.91s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 9: Successfully added to Neo4jVector.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  20%|██        | 9/45 [00:38<02:34,  4.29s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 10: Successfully added to Neo4jVector.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  22%|██▏       | 10/45 [00:43<02:36,  4.48s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 11: Successfully added to Neo4jVector.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  24%|██▍       | 11/45 [00:48<02:33,  4.52s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 12: Successfully added to Neo4jVector.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  27%|██▋       | 12/45 [00:53<02:34,  4.69s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 13: Successfully added to Neo4jVector.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  29%|██▉       | 13/45 [00:58<02:30,  4.69s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 14: Successfully added to Neo4jVector.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  31%|███       | 14/45 [01:02<02:20,  4.54s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 15: Successfully added to Neo4jVector.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  33%|███▎      | 15/45 [01:06<02:12,  4.40s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 16: Successfully added to Neo4jVector.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  36%|███▌      | 16/45 [01:10<02:03,  4.25s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 17: Successfully added to Neo4jVector.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  38%|███▊      | 17/45 [01:15<02:03,  4.41s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 18: Successfully added to Neo4jVector.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  40%|████      | 18/45 [01:18<01:53,  4.19s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 19: Successfully added to Neo4jVector.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  42%|████▏     | 19/45 [01:22<01:48,  4.17s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /embeddings in 2.533000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 20: Successfully added to Neo4jVector.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  44%|████▍     | 20/45 [01:30<02:11,  5.25s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /embeddings in 1.841000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 21: Successfully added to Neo4jVector.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  47%|████▋     | 21/45 [01:38<02:21,  5.90s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /embeddings in 1.684000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 22: Successfully added to Neo4jVector.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  49%|████▉     | 22/45 [01:43<02:14,  5.87s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /embeddings in 3.135000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 23: Successfully added to Neo4jVector.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  51%|█████     | 23/45 [01:50<02:17,  6.23s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /embeddings in 3.412000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 24: Successfully added to Neo4jVector.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  53%|█████▎    | 24/45 [01:59<02:26,  6.96s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /embeddings in 2.073000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 25: Successfully added to Neo4jVector.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  56%|█████▌    | 25/45 [02:07<02:23,  7.18s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /embeddings in 1.536000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 26: Successfully added to Neo4jVector.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  58%|█████▊    | 26/45 [02:12<02:07,  6.72s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /embeddings in 2.691000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 27: Successfully added to Neo4jVector.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  60%|██████    | 27/45 [02:20<02:06,  7.02s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /embeddings in 2.692000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 28: Successfully added to Neo4jVector.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  62%|██████▏   | 28/45 [02:28<02:02,  7.20s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /embeddings in 2.316000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 29: Successfully added to Neo4jVector.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  64%|██████▍   | 29/45 [02:35<01:53,  7.07s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /embeddings in 2.769000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 30: Successfully added to Neo4jVector.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  67%|██████▋   | 30/45 [02:42<01:49,  7.31s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /embeddings in 2.121000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 31: Successfully added to Neo4jVector.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  69%|██████▉   | 31/45 [02:51<01:48,  7.76s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /embeddings in 0.522000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 32: Successfully added to Neo4jVector.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  71%|███████   | 32/45 [02:57<01:32,  7.12s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /embeddings in 1.995000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 33: Successfully added to Neo4jVector.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  73%|███████▎  | 33/45 [03:05<01:28,  7.42s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /embeddings in 1.261000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 34: Successfully added to Neo4jVector.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  76%|███████▌  | 34/45 [03:11<01:18,  7.14s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /embeddings in 1.800000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 35: Successfully added to Neo4jVector.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  78%|███████▊  | 35/45 [03:19<01:12,  7.20s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /embeddings in 1.743000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 36: Successfully added to Neo4jVector.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  80%|████████  | 36/45 [03:24<01:00,  6.71s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /embeddings in 3.230000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 37: Successfully added to Neo4jVector.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  82%|████████▏ | 37/45 [03:36<01:04,  8.08s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 38: Successfully added to Neo4jVector.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  84%|████████▍ | 38/45 [03:40<00:48,  6.92s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /embeddings in 2.298000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 39: Successfully added to Neo4jVector.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  87%|████████▋ | 39/45 [03:48<00:44,  7.41s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /embeddings in 0.085000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 40: Successfully added to Neo4jVector.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  89%|████████▉ | 40/45 [03:54<00:34,  6.96s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /embeddings in 1.989000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 41: Successfully added to Neo4jVector.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  91%|█████████ | 41/45 [04:02<00:28,  7.09s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /embeddings in 1.838000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 42: Successfully added to Neo4jVector.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  93%|█████████▎| 42/45 [04:07<00:19,  6.65s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /embeddings in 3.275000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 43: Successfully added to Neo4jVector.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  96%|█████████▌| 43/45 [04:15<00:13,  6.83s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /embeddings in 3.039000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 44: Successfully added to Neo4jVector.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  98%|█████████▊| 44/45 [04:23<00:07,  7.22s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /embeddings in 1.683000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 45: Successfully added to Neo4jVector.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|██████████| 45/45 [04:30<00:00,  6.00s/it]\n"
     ]
    }
   ],
   "source": [
    "# Split documents into manageable batches\n",
    "batches = create_batches(documents, max_tokens_per_batch=max_tokens_per_batch)\n",
    "total_batches = len(batches)\n",
    "print(f\"Total Batches to Process: {total_batches}\")\n",
    "\n",
    "\n",
    "# Process each batch\n",
    "for i, batch in enumerate(tqdm(batches, desc=\"Processing Batches\")):\n",
    "    embed_and_add_batch(batch, embeddings, vector_store, batch_num=i+1)\n",
    "    time.sleep(1)  # Sleep for 1 second between batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: When did Airbnb go public?\n",
      "Answer: Airbnb went public on December 10, 2020.\n",
      "\n",
      "Sources:\n",
      "- Post title: Airbnb | Series number: Season 7, Episode 8 | File name: airbnb | Blog date: 2020-12-10\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "user_question = \"When did Airbnb go public?\"\n",
    "answer, sources = qa_pipeline(qa, user_question)\n",
    "\n",
    "print(f\"Question: {user_question}\")\n",
    "print(f\"Answer: {answer}\\n\")\n",
    "\n",
    "print(\"Sources:\")\n",
    "unique_sources = OrderedDict()\n",
    "\n",
    "for doc in sources:\n",
    "    # Combine multiple metadata fields for a richer source description\n",
    "    post_title = doc.metadata.get('post_title', 'No Title')\n",
    "    series_number = doc.metadata.get('series_number', 'No Series Info')\n",
    "    file_name = doc.metadata.get('file_name', 'No File Info')\n",
    "    date = doc.metadata.get('blog_date', 'No Date Info')\n",
    "    \n",
    "    # Format the source string with context (file_name)\n",
    "    source = f\"Post title: {post_title} | Series number: {series_number} | File name: {file_name} | Blog date: {date}\"\n",
    "    \n",
    "    # Use OrderedDict to maintain insertion order and uniqueness\n",
    "    unique_sources[source] = None\n",
    "\n",
    "# Print unique sources\n",
    "for source in unique_sources.keys():\n",
    "    print(f\"- {source}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grag-EOKyDehK-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
